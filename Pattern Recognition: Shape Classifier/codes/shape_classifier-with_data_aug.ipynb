{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.feature import canny \n",
    "import skimage\n",
    "from skimage import data, io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage import color "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists to save the labels (the name of the shape)\n",
    "train_dir = '/home/trojan/Desktop/pattern recognition/PB1/Implementation/data/shapes'\n",
    "shape_list = ['circle', 'triangle', 'tetragon', 'pentagon', 'other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(dir, Extension, th1, th2, x, y, deg, deg2, deg3):\n",
    "    for shape in shape_list:\n",
    "        for file_name in os.listdir(os.path.join(dir,shape)):\n",
    "            PATH = os.path.join(dir,shape)\n",
    "            img = os.path.join(dir,shape,file_name)\n",
    "            image = cv2.imread(img, 0)\n",
    "            \n",
    "            # flipping the image\n",
    "            image_xaxis_flipped = cv2.flip(image, 0)\n",
    "            image_yaxis_flipped = cv2.flip(image, 1)\n",
    "            \n",
    "            # Canny edge detect\n",
    "            image_canny = cv2.Canny(image,th1,th2)\n",
    "    \n",
    "            # Translation\n",
    "            rows, cols = image.shape\n",
    "            M_trans = np.float32([[1, 0, x], [0, 1, y]])\n",
    "            image_translated = cv2.warpAffine(image, M_trans, (cols, rows))\n",
    "            \n",
    "            # Rotation\n",
    "            rows, cols = image.shape\n",
    "            M_rot_90 = cv2.getRotationMatrix2D((cols/2,rows/2), deg, 1)\n",
    "            M_rot_180 = cv2.getRotationMatrix2D((cols/2,rows/2), deg2, 1)\n",
    "            M_rot_270 = cv2.getRotationMatrix2D((cols/2,rows/2), deg3, 1)\n",
    "            image_rotated_90 = cv2.warpAffine(image, M_rot_90, (cols, rows))\n",
    "            image_rotated_180 = cv2.warpAffine(image, M_rot_180, (cols, rows))\n",
    "            image_rotated_270 = cv2.warpAffine(image, M_rot_270, (cols, rows))\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "            cv2.imwrite(PATH + \"/flip-xaxis-\" + file_name, image_xaxis_flipped)\n",
    "            cv2.imwrite(PATH + \"/flip-yaxis-\" + file_name, image_yaxis_flipped)\n",
    "            cv2.imwrite(PATH + \"/Edge Canny-\" + file_name + str(th1) + \"*\" + str(th2) + Extension, image_canny)\n",
    "            cv2.imwrite(PATH + \"/Translation-\" + file_name + str(x) + str(y) + Extension, image_translated)\n",
    "            cv2.imwrite(PATH + \"/Rotate-90-\" + file_name + str(deg) + Extension, image_rotated_90)\n",
    "            cv2.imwrite(PATH + \"/Rotate-180-\" + file_name + str(deg) + Extension, image_rotated_180)\n",
    "            cv2.imwrite(PATH + \"/Rotate-270-\" + file_name + str(deg) + Extension, image_rotated_270)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation(train_dir, Extension='.png', th1=100, th2=200, x=20, y=20, deg=90, deg2=180, deg3=270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5\n",
    "num_trees = 100\n",
    "\n",
    "'''def preprocess(images, labels):\n",
    "    imgs = []\n",
    "    for image in images:\n",
    "        \n",
    "        #dataDim = np.prod(image.shape)\n",
    "        image = np.array(image)\n",
    "        #image = image.reshape(image, dataDim)\n",
    "        image = image.astype('float32')\n",
    "        image /=255\n",
    "        imgs.append(image)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return imgs, labels'''\n",
    "\n",
    "def preprocess(images, labels):\n",
    "\n",
    "    dataDim = np.prod(images[0].shape)\n",
    "    images = np.array(images)\n",
    "    images = images.reshape(len(images), dataDim)\n",
    "    images = images.astype('float32')\n",
    "    images /=255\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "#function to preprocess data\n",
    "def preprocess_flatten(images, labels):\n",
    "\n",
    "    features = []\n",
    "    for image in images:\n",
    "        feature = np.reshape(image, (300*300))\n",
    "        features.append(feature)\n",
    "        \n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def preprocess_canny_with_faltten(images, labels):\n",
    "    features = []\n",
    "    for i in range(len(images)):\n",
    "        \n",
    "        feature = canny((images[i]))\n",
    "        feature = np.reshape(feature, (300*300))\n",
    "        features.append(feature)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def preprocess_PCA_with_flatten(images, labels):\n",
    "    features = []\n",
    "    for i in range(len(images)):\n",
    "\n",
    "        image_pca = PCA().fit_transform(images[i])\n",
    "        image_selected = image_pca[:,:2]\n",
    "        image_selected = np.reshape(image_selected, (600))\n",
    "        features.append(image_selected)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def preprocess_canny_and_PCA_with_flatten(images, labels):\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(images)):\n",
    "        \n",
    "        edges = canny((images[i]))\n",
    "        image_pca = PCA().fit_transform(edges)\n",
    "        image_selected = image_pca[:,:2]\n",
    "        image_selected = np.reshape(image_selected, (600))\n",
    "        features.append(image_selected)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "def augmentation(images, labels):\n",
    "    #for img, label in zip(images, labels)\n",
    "    for img in images:\n",
    "        height, width = img.shape[:2]\n",
    "        M = np.float32([[1, 0, 100], [0, 1, 50]])\n",
    "        translated = cv2.warpAffine(img, M, (width, height))\n",
    "        #flipped = cv2.flip(img, 1)\n",
    "\n",
    "        #center = (width // 2, height // 2)\n",
    "        #R = cv2.getRotationMatrix2D(center, 60, 1.0)\n",
    "        #rotated = cv2.warpAffine(img, R, (width, height))\n",
    "        #labels.append(label)\n",
    "        images.append(translated)\n",
    "        #images.append(flipped)\n",
    "        #images.append(rotated)\n",
    "        \n",
    "    for label in labels:\n",
    "        labels.append(label)\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "# function to make classifier\n",
    "def classify(model, images, labels):\n",
    "\n",
    "    model.fit(images, labels)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    models = []\n",
    "    names = []\n",
    "    models.append(('KNN', KNeighborsClassifier(n_neighbors=4)))\n",
    "    models.append(('LR', LogisticRegression(random_state=seed, max_iter=100)))\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('CART', DecisionTreeClassifier(random_state=seed)))\n",
    "    models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    models.append(('SVM', SVC(random_state=seed)))\n",
    "    \n",
    "    #iterate through each shape\n",
    "    all_labels, all_images = [],[]\n",
    "    for shape in shape_list:\n",
    "        print('Getting data for: ', shape)\n",
    "        for file_name in os.listdir(os.path.join(train_dir,shape)):\n",
    "            all_images.append(cv2.imread(os.path.join(train_dir,shape,file_name), 0))\n",
    "            #add an integer to the labels list\n",
    "            all_labels.append(shape_list.index(shape))\n",
    "\n",
    "    # train and validation split\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(all_images, all_labels, \n",
    "                                                                          shuffle=True, stratify=all_labels, \n",
    "                                                                          test_size=0.1, random_state=42)\n",
    "\n",
    "    print('Number of training images: ', len(train_images), '\\n')\n",
    "\n",
    "    # Preprocess (your own function)\n",
    "    train_images, train_labels = preprocess_PCA_with_flatten(train_images, train_labels)\n",
    "    val_images, val_labels = preprocess_PCA_with_flatten(val_images, val_labels)\n",
    "\n",
    "    for name, model in models:\n",
    "        #train_images, train_labels = preprocess(train_images, train_labels)\n",
    "        print (name)\n",
    "        \n",
    "        # Make a classifier (your own function)\n",
    "        model = classify(model, train_images, train_labels)\n",
    "\n",
    "        # Predict the labels from the model (your own code depending the output of the train function)\n",
    "        pred_labels = model.predict(train_images)\n",
    "\n",
    "        # Calculate accuracy (Do not erase or modify here)\n",
    "        pred_acc = np.sum(pred_labels==train_labels)/len(train_labels)*100\n",
    "        print(\"Accuracy = {}\".format(pred_acc))\n",
    "\n",
    "        cm = metrics.confusion_matrix(train_labels, pred_labels)\n",
    "        print(cm, '\\n')\n",
    "        \n",
    "        # Validation\n",
    "        print('Number of validation images: ', len(val_images))\n",
    "    \n",
    "        pred_val_labels = model.predict(val_images)\n",
    "        val_acc = np.sum(pred_val_labels==val_labels)/len(val_labels)*100\n",
    "        print(\"Val Accuracy = {}\".format(val_acc), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for:  circle\n",
      "Getting data for:  triangle\n",
      "Getting data for:  tetragon\n",
      "Getting data for:  pentagon\n",
      "Getting data for:  other\n",
      "Number of training images:  180 \n",
      "\n",
      "KNN\n",
      "Accuracy = 61.111111111111114\n",
      "[[28  7  0  0  1]\n",
      " [ 7 28  0  0  1]\n",
      " [ 7 11 15  2  1]\n",
      " [ 8  7  2 15  4]\n",
      " [ 5  6  0  1 24]] \n",
      "\n",
      "Number of validation images:  20\n",
      "Val Accuracy = 40.0 \n",
      "\n",
      "LR\n",
      "Accuracy = 100.0\n",
      "[[36  0  0  0  0]\n",
      " [ 0 36  0  0  0]\n",
      " [ 0  0 36  0  0]\n",
      " [ 0  0  0 36  0]\n",
      " [ 0  0  0  0 36]] \n",
      "\n",
      "Number of validation images:  20\n",
      "Val Accuracy = 35.0 \n",
      "\n",
      "LDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trojan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.66666666666667\n",
      "[[35  1  0  0  0]\n",
      " [ 1 33  1  0  1]\n",
      " [ 0  1 35  0  0]\n",
      " [ 0  1  0 35  0]\n",
      " [ 0  0  0  0 36]] \n",
      "\n",
      "Number of validation images:  20\n",
      "Val Accuracy = 25.0 \n",
      "\n",
      "CART\n",
      "Accuracy = 100.0\n",
      "[[36  0  0  0  0]\n",
      " [ 0 36  0  0  0]\n",
      " [ 0  0 36  0  0]\n",
      " [ 0  0  0 36  0]\n",
      " [ 0  0  0  0 36]] \n",
      "\n",
      "Number of validation images:  20\n",
      "Val Accuracy = 60.0 \n",
      "\n",
      "RF\n",
      "Accuracy = 100.0\n",
      "[[36  0  0  0  0]\n",
      " [ 0 36  0  0  0]\n",
      " [ 0  0 36  0  0]\n",
      " [ 0  0  0 36  0]\n",
      " [ 0  0  0  0 36]] \n",
      "\n",
      "Number of validation images:  20\n",
      "Val Accuracy = 50.0 \n",
      "\n",
      "NB\n",
      "Accuracy = 58.333333333333336\n",
      "[[29  1  1  1  4]\n",
      " [ 8 20  0  4  4]\n",
      " [ 6  3 18  5  4]\n",
      " [ 8  5  1 21  1]\n",
      " [12  0  2  5 17]] \n",
      "\n",
      "Number of validation images:  20\n",
      "Val Accuracy = 40.0 \n",
      "\n",
      "SVM\n",
      "Accuracy = 73.88888888888889\n",
      "[[28  3  2  0  3]\n",
      " [ 6 27  0  0  3]\n",
      " [ 5  2 27  0  2]\n",
      " [ 8  3  2 23  0]\n",
      " [ 6  0  2  0 28]] \n",
      "\n",
      "Number of validation images:  20\n",
      "Val Accuracy = 50.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forTA (Do not erase here)\\ntest_dir = \\'../ForTA\\'\\ntest_labels, test_images = [], []\\nfor shape in shape_list:\\n    print(\\'Getting data for: \\', shape)\\n    for file_name in os.listdir(os.path.join(test_dir,shape)):\\n        test_images.append(cv2.imread(os.path.join(test_dir,shape,file_name), 0))\\n        #add an integer to the labels list\\n        test_labels.append(shape_list.index(shape))\\n\\nprint(\\'Number of test images: \\', len(test_images))\\n\\ntest_images, test_labels = preprocess(test_images, test_labels)\\npred_labels = model.predict(test_images)\\npred_acc = np.sum(pred_labels==test_labels)/len(test_labels)*100\\nprint(\"Test Accuracy = {}\".format(pred_acc))\\n'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \"\"\"forTA (Do not erase here)\n",
    "    test_dir = '../ForTA'\n",
    "    test_labels, test_images = [], []\n",
    "    for shape in shape_list:\n",
    "        print('Getting data for: ', shape)\n",
    "        for file_name in os.listdir(os.path.join(test_dir,shape)):\n",
    "            test_images.append(cv2.imread(os.path.join(test_dir,shape,file_name), 0))\n",
    "            #add an integer to the labels list\n",
    "            test_labels.append(shape_list.index(shape))\n",
    "\n",
    "    print('Number of test images: ', len(test_images))\n",
    "\n",
    "    test_images, test_labels = preprocess(test_images, test_labels)\n",
    "    pred_labels = model.predict(test_images)\n",
    "    pred_acc = np.sum(pred_labels==test_labels)/len(test_labels)*100\n",
    "    print(\"Test Accuracy = {}\".format(pred_acc))\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
