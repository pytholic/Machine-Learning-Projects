{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.feature import canny \n",
    "import skimage\n",
    "from skimage import data, io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage import color "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists to save the labels (the name of the shape)\n",
    "train_dir = '/home/trojan/Desktop/pattern recognition/PB1/Implementation/data/shapes'\n",
    "shape_list = ['circle', 'triangle', 'tetragon', 'pentagon', 'other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5\n",
    "num_trees = 100\n",
    "\n",
    "#function to preprocess data\n",
    "def preprocess_flatten(images, labels):\n",
    "\n",
    "    features = []\n",
    "    for image in images:\n",
    "        feature = np.reshape(image, (300*300))\n",
    "        features.append(feature)\n",
    "        \n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def preprocess_canny_with_faltten(images, labels):\n",
    "    features = []\n",
    "    for i in range(len(images)):\n",
    "        \n",
    "        feature = canny((images[i]))\n",
    "        feature = np.reshape(feature, (300*300))\n",
    "        features.append(feature)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def preprocess_PCA_with_flatten(images, labels):\n",
    "    features = []\n",
    "    for i in range(len(images)):\n",
    "\n",
    "        image_pca = PCA().fit_transform(images[i])\n",
    "        image_selected = image_pca[:,:2]\n",
    "        image_selected = np.reshape(image_selected, (600))\n",
    "        features.append(image_selected)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def preprocess_canny_and_PCA_with_flatten(images, labels):\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(images)):\n",
    "        \n",
    "        edges = canny((images[i]))\n",
    "        image_pca = PCA().fit_transform(edges)\n",
    "        image_selected = image_pca[:,:2]\n",
    "        image_selected = np.reshape(image_selected, (600))\n",
    "        features.append(image_selected)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "def augmentation(images, labels):\n",
    "    #for img, label in zip(images, labels)\n",
    "    for img in images:\n",
    "        height, width = img.shape[:2]\n",
    "        M = np.float32([[1, 0, 100], [0, 1, 50]])\n",
    "        translated = cv2.warpAffine(img, M, (width, height))\n",
    "        #flipped = cv2.flip(img, 1)\n",
    "\n",
    "        #center = (width // 2, height // 2)\n",
    "        #R = cv2.getRotationMatrix2D(center, 60, 1.0)\n",
    "        #rotated = cv2.warpAffine(img, R, (width, height))\n",
    "        #labels.append(label)\n",
    "        images.append(translated)\n",
    "        #images.append(flipped)\n",
    "        #images.append(rotated)\n",
    "        \n",
    "    for label in labels:\n",
    "        labels.append(label)\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "# function to make classifier\n",
    "def classify(model, images, labels):\n",
    "\n",
    "    model.fit(images, labels)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for:  circle\n",
      "Getting data for:  triangle\n",
      "Getting data for:  tetragon\n",
      "Getting data for:  pentagon\n",
      "Getting data for:  other\n",
      "Number of training images:  20 \n",
      "\n",
      "Number of training labels:  20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_labels, all_images = [],[]\n",
    "for shape in shape_list:\n",
    "    print('Getting data for: ', shape)\n",
    "    for file_name in os.listdir(os.path.join(train_dir,shape)):\n",
    "        all_images.append(cv2.imread(os.path.join(train_dir,shape,file_name), 0))\n",
    "        #add an integer to the labels list\n",
    "        all_labels.append(shape_list.index(shape))\n",
    "\n",
    "# train and validation split\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(all_images, all_labels, \n",
    "                                                                          shuffle=True, stratify=all_labels, \n",
    "                                                                          test_size=0.2, random_state=42)\n",
    "\n",
    "print('Number of training images: ', len(train_images), '\\n')\n",
    "print('Number of training labels: ', len(train_labels), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of aug images: ', 5, '\\n')\n",
      "('Number of aug labels: ', 5, '\\n')\n"
     ]
    }
   ],
   "source": [
    "aug_images = []\n",
    "aug_labels = []\n",
    "for i in range (0, 5):\n",
    "    aug_images.append(train_images[i])\n",
    "    aug_labels.append(train_labels[i])\n",
    "\n",
    "print(('Number of aug images: ', len(aug_images), '\\n'))\n",
    "print(('Number of aug labels: ', len(aug_labels), '\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_aug_images, new_aug_labels = augmentation (aug_images, aug_labels)\n",
    "\n",
    "print(('New number of aug images: ', len(aug_images), '\\n'))\n",
    "print(('New number of aug labels: ', len(aug_labels), '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    models = []\n",
    "    names = []\n",
    "    models.append(('KNN', KNeighborsClassifier(n_neighbors=2)))\n",
    "    models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('CART', DecisionTreeClassifier(random_state=seed)))\n",
    "    models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    models.append(('SVM', SVC(random_state=seed)))\n",
    "    \n",
    "    #iterate through each shape\n",
    "    all_labels, all_images = [],[]\n",
    "    for shape in shape_list:\n",
    "        print('Getting data for: ', shape)\n",
    "        for file_name in os.listdir(os.path.join(train_dir,shape)):\n",
    "            all_images.append(cv2.imread(os.path.join(train_dir,shape,file_name), 0))\n",
    "            #add an integer to the labels list\n",
    "            all_labels.append(shape_list.index(shape))\n",
    "\n",
    "    # train and validation split\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(all_images, all_labels, \n",
    "                                                                          shuffle=True, stratify=all_labels, \n",
    "                                                                          test_size=0.2, random_state=42)\n",
    "\n",
    "    print('Number of training images: ', len(train_images), '\\n')\n",
    "\n",
    "    # Preprocess (your own function)\n",
    "    train_images, train_labels = preprocess_canny_and_PCA_with_flatten(train_images, train_labels)\n",
    "    val_images, val_labels = preprocess_canny_and_PCA_with_flatten(val_images, val_labels)\n",
    "\n",
    "    for name, model in models:\n",
    "        #train_images, train_labels = preprocess(train_images, train_labels)\n",
    "        print (name)\n",
    "        \n",
    "        # Make a classifier (your own function)\n",
    "        model = classify(model, train_images, train_labels)\n",
    "\n",
    "        # Predict the labels from the model (your own code depending the output of the train function)\n",
    "        pred_labels = model.predict(train_images)\n",
    "\n",
    "        # Calculate accuracy (Do not erase or modify here)\n",
    "        pred_acc = np.sum(pred_labels==train_labels)/len(train_labels)*100\n",
    "        print(\"Accuracy = {}\".format(pred_acc))\n",
    "\n",
    "        cm = metrics.confusion_matrix(train_labels, pred_labels)\n",
    "        print(cm, '\\n')\n",
    "        \n",
    "        # Validation\n",
    "        print('Number of validation images: ', len(val_images))\n",
    "    \n",
    "        pred_val_labels = model.predict(val_images)\n",
    "        val_acc = np.sum(pred_val_labels==val_labels)/len(val_labels)*100\n",
    "        print(\"Val Accuracy = {}\".format(val_acc), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for:  circle\n",
      "Getting data for:  triangle\n",
      "Getting data for:  tetragon\n",
      "Getting data for:  pentagon\n",
      "Getting data for:  other\n",
      "Number of training images:  20 \n",
      "\n",
      "KNN\n",
      "Accuracy = 55.00000000000001\n",
      "[[4 0 0 0 0]\n",
      " [0 4 0 0 0]\n",
      " [0 2 2 0 0]\n",
      " [0 3 0 1 0]\n",
      " [1 3 0 0 0]] \n",
      "\n",
      "Number of validation images:  5\n",
      "Val Accuracy = 20.0 \n",
      "\n",
      "LR\n",
      "Accuracy = 100.0\n",
      "[[4 0 0 0 0]\n",
      " [0 4 0 0 0]\n",
      " [0 0 4 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 4]] \n",
      "\n",
      "Number of validation images:  5\n",
      "Val Accuracy = 40.0 \n",
      "\n",
      "LDA\n",
      "Accuracy = 65.0\n",
      "[[2 1 0 0 1]\n",
      " [1 3 0 0 0]\n",
      " [1 1 2 0 0]\n",
      " [0 1 0 3 0]\n",
      " [0 0 0 1 3]] \n",
      "\n",
      "Number of validation images:  5\n",
      "Val Accuracy = 40.0 \n",
      "\n",
      "CART\n",
      "Accuracy = 100.0\n",
      "[[4 0 0 0 0]\n",
      " [0 4 0 0 0]\n",
      " [0 0 4 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 4]] \n",
      "\n",
      "Number of validation images:  5\n",
      "Val Accuracy = 20.0 \n",
      "\n",
      "RF\n",
      "Accuracy = 100.0\n",
      "[[4 0 0 0 0]\n",
      " [0 4 0 0 0]\n",
      " [0 0 4 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 4]] \n",
      "\n",
      "Number of validation images:  5\n",
      "Val Accuracy = 40.0 \n",
      "\n",
      "NB\n",
      "Accuracy = 100.0\n",
      "[[4 0 0 0 0]\n",
      " [0 4 0 0 0]\n",
      " [0 0 4 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 4]] \n",
      "\n",
      "Number of validation images:  5\n",
      "Val Accuracy = 20.0 \n",
      "\n",
      "SVM\n",
      "Accuracy = 95.0\n",
      "[[4 0 0 0 0]\n",
      " [0 4 0 0 0]\n",
      " [0 0 4 0 0]\n",
      " [0 1 0 3 0]\n",
      " [0 0 0 0 4]] \n",
      "\n",
      "Number of validation images:  5\n",
      "Val Accuracy = 40.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forTA (Do not erase here)\\ntest_dir = \\'../ForTA\\'\\ntest_labels, test_images = [], []\\nfor shape in shape_list:\\n    print(\\'Getting data for: \\', shape)\\n    for file_name in os.listdir(os.path.join(test_dir,shape)):\\n        test_images.append(cv2.imread(os.path.join(test_dir,shape,file_name), 0))\\n        #add an integer to the labels list\\n        test_labels.append(shape_list.index(shape))\\n\\nprint(\\'Number of test images: \\', len(test_images))\\n\\ntest_images, test_labels = preprocess(test_images, test_labels)\\npred_labels = model.predict(test_images)\\npred_acc = np.sum(pred_labels==test_labels)/len(test_labels)*100\\nprint(\"Test Accuracy = {}\".format(pred_acc))\\n'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \"\"\"forTA (Do not erase here)\n",
    "    test_dir = '../ForTA'\n",
    "    test_labels, test_images = [], []\n",
    "    for shape in shape_list:\n",
    "        print('Getting data for: ', shape)\n",
    "        for file_name in os.listdir(os.path.join(test_dir,shape)):\n",
    "            test_images.append(cv2.imread(os.path.join(test_dir,shape,file_name), 0))\n",
    "            #add an integer to the labels list\n",
    "            test_labels.append(shape_list.index(shape))\n",
    "\n",
    "    print('Number of test images: ', len(test_images))\n",
    "\n",
    "    test_images, test_labels = preprocess(test_images, test_labels)\n",
    "    pred_labels = model.predict(test_images)\n",
    "    pred_acc = np.sum(pred_labels==test_labels)/len(test_labels)*100\n",
    "    print(\"Test Accuracy = {}\".format(pred_acc))\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
