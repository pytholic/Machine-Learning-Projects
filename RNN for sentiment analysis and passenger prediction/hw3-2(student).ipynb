{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_problem2(student ver).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2jEftKY46mw",
        "colab_type": "text"
      },
      "source": [
        "# Homework 3 Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HoUkSsB49SK",
        "colab_type": "text"
      },
      "source": [
        "In this homework, you will implement LSTM models to predict the number of passengers at Seoul Station, Gangnam Station, and Yeouido Station. We'll provide you with basic skeleton codes with LSTM model. However, provided codes can be improved with some simple modifications. The purpose of this task is to implement code that solves the regression problem of estimating the number of passengers through LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw_uqFeC5DYt",
        "colab_type": "text"
      },
      "source": [
        "## Google Drive Mount (If you are not using CoLab, you can skip this process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hiNO3TF5Jvz",
        "colab_type": "text"
      },
      "source": [
        "First, you need to access train.csv and test.csv from Google Drive to use the provided these files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRXyWuf-PePm",
        "colab_type": "code",
        "outputId": "9073f1e5-11c4-495d-c2a8-a990c6356b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7TrRKMd9nRD",
        "colab_type": "text"
      },
      "source": [
        "## Train and Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46gokJUX814W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import copy\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYn4Hixj0dCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('/content/gdrive/My Drive/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbWF3iwl7jbr",
        "colab_type": "code",
        "outputId": "44ca2854-9fbc-4b47-a744-fdb1a2656640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>station name</th>\n",
              "      <th>05 ~ 06</th>\n",
              "      <th>06 ~ 07</th>\n",
              "      <th>07 ~ 08</th>\n",
              "      <th>08 ~ 09</th>\n",
              "      <th>09 ~ 10</th>\n",
              "      <th>10 ~ 11</th>\n",
              "      <th>11 ~ 12</th>\n",
              "      <th>12 ~ 13</th>\n",
              "      <th>13 ~ 14</th>\n",
              "      <th>14 ~ 15</th>\n",
              "      <th>15 ~ 16</th>\n",
              "      <th>16 ~ 17</th>\n",
              "      <th>17 ~ 18</th>\n",
              "      <th>18 ~ 19</th>\n",
              "      <th>19 ~ 20</th>\n",
              "      <th>20 ~ 21</th>\n",
              "      <th>21 ~ 22</th>\n",
              "      <th>22 ~ 23</th>\n",
              "      <th>23 ~ 24</th>\n",
              "      <th>00 ~ 01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018.1.1</td>\n",
              "      <td>Seoul Station</td>\n",
              "      <td>373</td>\n",
              "      <td>318</td>\n",
              "      <td>365</td>\n",
              "      <td>785</td>\n",
              "      <td>1047</td>\n",
              "      <td>1576</td>\n",
              "      <td>2510</td>\n",
              "      <td>3233</td>\n",
              "      <td>3145</td>\n",
              "      <td>2443</td>\n",
              "      <td>2980</td>\n",
              "      <td>3476</td>\n",
              "      <td>3891</td>\n",
              "      <td>3227</td>\n",
              "      <td>2945</td>\n",
              "      <td>2382</td>\n",
              "      <td>3070</td>\n",
              "      <td>1750</td>\n",
              "      <td>781</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018.1.2</td>\n",
              "      <td>Seoul Station</td>\n",
              "      <td>390</td>\n",
              "      <td>546</td>\n",
              "      <td>1936</td>\n",
              "      <td>2840</td>\n",
              "      <td>1767</td>\n",
              "      <td>1960</td>\n",
              "      <td>2935</td>\n",
              "      <td>3079</td>\n",
              "      <td>3175</td>\n",
              "      <td>2527</td>\n",
              "      <td>3239</td>\n",
              "      <td>3872</td>\n",
              "      <td>4943</td>\n",
              "      <td>9210</td>\n",
              "      <td>5214</td>\n",
              "      <td>3124</td>\n",
              "      <td>3321</td>\n",
              "      <td>1901</td>\n",
              "      <td>932</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018.1.3</td>\n",
              "      <td>Seoul Station</td>\n",
              "      <td>373</td>\n",
              "      <td>435</td>\n",
              "      <td>1443</td>\n",
              "      <td>2595</td>\n",
              "      <td>1712</td>\n",
              "      <td>2055</td>\n",
              "      <td>2402</td>\n",
              "      <td>2839</td>\n",
              "      <td>2839</td>\n",
              "      <td>2431</td>\n",
              "      <td>3133</td>\n",
              "      <td>3313</td>\n",
              "      <td>5109</td>\n",
              "      <td>9311</td>\n",
              "      <td>4799</td>\n",
              "      <td>2998</td>\n",
              "      <td>3117</td>\n",
              "      <td>1852</td>\n",
              "      <td>938</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018.1.4</td>\n",
              "      <td>Seoul Station</td>\n",
              "      <td>453</td>\n",
              "      <td>470</td>\n",
              "      <td>1379</td>\n",
              "      <td>2625</td>\n",
              "      <td>1716</td>\n",
              "      <td>1857</td>\n",
              "      <td>2645</td>\n",
              "      <td>2846</td>\n",
              "      <td>2980</td>\n",
              "      <td>2568</td>\n",
              "      <td>3267</td>\n",
              "      <td>3472</td>\n",
              "      <td>4737</td>\n",
              "      <td>9037</td>\n",
              "      <td>4847</td>\n",
              "      <td>3196</td>\n",
              "      <td>3422</td>\n",
              "      <td>2130</td>\n",
              "      <td>1110</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018.1.5</td>\n",
              "      <td>Seoul Station</td>\n",
              "      <td>419</td>\n",
              "      <td>506</td>\n",
              "      <td>1407</td>\n",
              "      <td>2504</td>\n",
              "      <td>1839</td>\n",
              "      <td>1930</td>\n",
              "      <td>2564</td>\n",
              "      <td>2946</td>\n",
              "      <td>3171</td>\n",
              "      <td>2636</td>\n",
              "      <td>3931</td>\n",
              "      <td>4381</td>\n",
              "      <td>5951</td>\n",
              "      <td>10146</td>\n",
              "      <td>5874</td>\n",
              "      <td>3527</td>\n",
              "      <td>3825</td>\n",
              "      <td>2740</td>\n",
              "      <td>1323</td>\n",
              "      <td>241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       date   station name  05 ~ 06  ...  22 ~ 23  23 ~ 24  00 ~ 01\n",
              "0  2018.1.1  Seoul Station      373  ...     1750      781       96\n",
              "1  2018.1.2  Seoul Station      390  ...     1901      932      130\n",
              "2  2018.1.3  Seoul Station      373  ...     1852      938      146\n",
              "3  2018.1.4  Seoul Station      453  ...     2130     1110      170\n",
              "4  2018.1.5  Seoul Station      419  ...     2740     1323      241\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFwyiQl98XnB",
        "colab_type": "text"
      },
      "source": [
        "The data consists of date, station name, and number of passengers per hour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r492EBaGAoW6",
        "colab_type": "text"
      },
      "source": [
        "We will implement a model that predicts the number of passengers after an hour with the current number of passengers as input. For example, when we know that the number of passengers from 05 ~ 06 in 2018.1.1 Seoul Station is 373, we want a model to predict the number of passengers (318) in 06 ~ 07. (It is assumed that the number of passengers before 05 ~ 06 is 0.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTVSng469vDv",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5T-8ZTC6kna",
        "colab_type": "text"
      },
      "source": [
        "Import basic modules (If you need other modules, you can import additional modules.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poxtSLmP0q4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty8JO6piPYnc",
        "colab_type": "text"
      },
      "source": [
        "## Step 1) Base Encoding Version (4pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AsWsB65_w2O",
        "colab_type": "text"
      },
      "source": [
        "We need to encode the data to use train and test data as input to the LSTM model.\n",
        "We'll do a very simple encoding first.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMaWV0qGDFhe",
        "colab_type": "text"
      },
      "source": [
        "Dataset Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj7EhDKSDP1a",
        "colab_type": "text"
      },
      "source": [
        "As for the data we need to process, 20 data from 05:00 to 00:00 must be processed as one sequential data. Reflecting this, we construct the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCXGvkrwDvEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "station_one_hot_dict = {\n",
        "    \"Seoul Station\": [1, 0, 0],\n",
        "    \"Gangnam\": [0, 1, 0],\n",
        "    \"Yeouido\": [0, 0, 1]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnKokkWSEaoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_lst = ['05 ~ 06', '06 ~ 07', '07 ~ 08', '08 ~ 09', '09 ~ 10', '10 ~ 11', '11 ~ 12', \n",
        "            '12 ~ 13', '13 ~ 14', '14 ~ 15', '15 ~ 16', '16 ~ 17', '17 ~ 18', '18 ~ 19', \n",
        "            '19 ~ 20', '20 ~ 21', '21 ~ 22', '22 ~ 23', '23 ~ 24', '00 ~ 01']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t-ofbtj7AIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('/content/gdrive/My Drive/train.csv', 'r')\n",
        "rdr = csv.reader(f)\n",
        "\n",
        "next(rdr)\n",
        "\n",
        "train_inflow_seq_data_x = []\n",
        "train_inflow_seq_data_y = []\n",
        "\n",
        "\n",
        "for line in rdr:\n",
        "    date = line[0]\n",
        "    station_name = line[1]\n",
        "    inflow_lst = line[2:]\n",
        "    \n",
        "    one_hot_station_name = station_one_hot_dict[station_name]\n",
        "    \n",
        "    train_data_x_lst = []\n",
        "    train_data_y_lst = []\n",
        "   \n",
        "    for idx, (inflow, time) in enumerate(zip(inflow_lst, time_lst)):\n",
        "        \n",
        "        if idx == 0:\n",
        "            previous_inflow = [0]\n",
        "        else:\n",
        "            previous_inflow = [int(inflow_lst[idx-1].strip().replace(\",\", \"\"))]\n",
        "        \n",
        "        data_x = one_hot_station_name + previous_inflow\n",
        "        data_y = int(inflow.strip().replace(\",\", \"\"))\n",
        "\n",
        "        train_data_x_lst.append(data_x)\n",
        "        train_data_y_lst.append(data_y)\n",
        "    \n",
        "    train_inflow_seq_data_x.append(copy.deepcopy(train_data_x_lst))\n",
        "    train_inflow_seq_data_y.append(copy.deepcopy(train_data_y_lst))\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZqXYnaJErlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('/content/gdrive/My Drive/test.csv', 'r')\n",
        "rdr = csv.reader(f)\n",
        "\n",
        "next(rdr)\n",
        "\n",
        "valid_inflow_seq_data_x = []\n",
        "valid_inflow_seq_data_y = []\n",
        "\n",
        "\n",
        "for line in rdr:\n",
        "    date = line[0]\n",
        "    station_name = line[1]\n",
        "    inflow_lst = line[2:]\n",
        "    \n",
        "    one_hot_station_name = station_one_hot_dict[station_name]\n",
        "    \n",
        "    valid_data_x_lst = []\n",
        "    valid_data_y_lst = []\n",
        "   \n",
        "    for idx, (inflow, time) in enumerate(zip(inflow_lst, time_lst)):\n",
        "        \n",
        "        if idx == 0:\n",
        "            previous_inflow = [0]\n",
        "        else:\n",
        "            previous_inflow = [int(inflow_lst[idx-1].strip().replace(\",\", \"\"))]\n",
        "        \n",
        "        data_x = one_hot_station_name + previous_inflow\n",
        "        data_y = int(inflow.strip().replace(\",\", \"\"))\n",
        "\n",
        "        valid_data_x_lst.append(data_x)\n",
        "        valid_data_y_lst.append(data_y)\n",
        "    \n",
        "    valid_inflow_seq_data_x.append(copy.deepcopy(valid_data_x_lst))\n",
        "    valid_inflow_seq_data_y.append(copy.deepcopy(valid_data_y_lst))\n",
        "\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTf3BoEVE_NV",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZHzT55XFHl9",
        "colab_type": "text"
      },
      "source": [
        "We will use the RMSE as loss function as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPE30M8sExMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RMSELoss(yhat,y):\n",
        "    return torch.sqrt(torch.mean((yhat-y)**2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNPTPAHLFGH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.005\n",
        "TOTAL_EPOCH = 1000\n",
        "GPU_DEVICE = 0\n",
        "\n",
        "NUM_CLASS = 1\n",
        "INPUT_SIZE = 4\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_LAYERS = 2\n",
        "SEQUENCE_LENGTH = 20\n",
        "\n",
        "CRITERION = RMSELoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANTSn-cVGYC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inflow_seq_data_x = np.array(train_inflow_seq_data_x, dtype=np.float32)\n",
        "train_inflow_seq_data_y = np.array(train_inflow_seq_data_y, dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkpIuapJGaO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inflow_seq_data_x = torch.from_numpy(train_inflow_seq_data_x)\n",
        "train_inflow_seq_data_y = torch.from_numpy(train_inflow_seq_data_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e69rWHB2Gbm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = list(zip(train_inflow_seq_data_x, train_inflow_seq_data_y))\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKBrWKfGOXIw",
        "colab_type": "code",
        "outputId": "0ea95149-2791-4d95-819c-fb98bc581c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_inflow_seq_data_x[0][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1.,   0.,   0., 373.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZzG2RBwHucf",
        "colab_type": "text"
      },
      "source": [
        "### LSTM Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "behuMJQEH3Wg",
        "colab_type": "text"
      },
      "source": [
        "[Problem 1] \n",
        "In the code below, put the appropriate code in '?' so that the code works fine. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNOJtWWzGdDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.num_classes = NUM_CLASS\n",
        "        self.num_layers = NUM_LAYERS\n",
        "        self.input_size = INPUT_SIZE\n",
        "        self.hidden_size = HIDDEN_SIZE\n",
        "        self.sequence_length = SEQUENCE_LENGTH\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(?, ?, ?)) # (0.25 pt)\n",
        "        \n",
        "        c_0 = Variable(torch.zeros(?, ?, ?)) # (0.25 pt)\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        ula, (h_out, c_out) = self.lstm(?, (?, ?)) # (0.25 pt)\n",
        "        \n",
        "        out = self.fc(?) # (0.25 pt)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJU1ia-DnuDw",
        "colab_type": "text"
      },
      "source": [
        "[Problem 2] \n",
        "In the code below, put the appropriate code in '?' so that the code works fine. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7CAeEHkGfeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(model, train_loader, criterion, learning_rate, num_epochs):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, data in enumerate(train_loader):\n",
        "            input_x = data[0].type(torch.FloatTensor).cuda(GPU_DEVICE)\n",
        "            target = data[1].type(torch.FloatTensor).cuda(GPU_DEVICE)\n",
        "            \n",
        "            output = ? # 0.5 pt\n",
        "            \n",
        "            loss = ? # 0.5 pt\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NV1VN6gGohY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = LSTM().cuda(GPU_DEVICE)\n",
        "fit(net, train_loader, CRITERION, LEARNING_RATE, TOTAL_EPOCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMN2YsoXJdfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write code to measure RMSE on test data and print RMSE. (Calculate RMSE in full-batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzO4ioG9J7JD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_inflow_seq_data_x = np.array(valid_inflow_seq_data_x, dtype=np.float32)\n",
        "valid_inflow_seq_data_y = np.array(valid_inflow_seq_data_y, dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr5EVKkaKA7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_inflow_seq_data_x = torch.from_numpy(valid_inflow_seq_data_x)\n",
        "valid_inflow_seq_data_y = torch.from_numpy(valid_inflow_seq_data_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gZA5VhsopYc",
        "colab_type": "text"
      },
      "source": [
        "[Problem 3] Write code to measure RMSE on test data and print RMSE. (Calculate RMSE in full-batch) (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOUU7V9VKCQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_dataset = ? # 0.25 pt\n",
        "valid_loader = ? # 0.25 pt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCDaG29WKcFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write code to measure RMSE on test data and print RMSE (1.5 pt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvr0f9CrKJBA",
        "colab_type": "text"
      },
      "source": [
        "## Step2) LSTM model using encoding data with time information added (6pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18J82vR2Kyn4",
        "colab_type": "text"
      },
      "source": [
        "We used a very simple encoding above as input. However, the input of the above model did not reflect the temporal factor. You have to make the input data by adding time information by referring to the code above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnJesMotNdHL",
        "colab_type": "text"
      },
      "source": [
        "The encoding you need to add is a one-hot vector for the day of the week(7) and times(20).\n",
        "The days of the week are represented as 7-dimensional one-hot vectors from Monday to Sunday.\n",
        "Time information is expressed as 20-dimensional one-hot vectors from '05 ~ 06' to '00 ~ 01'.\n",
        "For example, if you represent the data corresponding to '06 ~ 07' of '2018.1.1' Seoul Station, it would be as follows.\n",
        "[1, 0, 0, 373] + [1, 0, 0, 0, 0, 0, 0] + [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 , 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxalMAy9R5Bg",
        "colab_type": "text"
      },
      "source": [
        "You can use the code below if you want to use it, or you can implement it yourself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvq46AH2R4nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_lst = ['05 ~ 06', '06 ~ 07', '07 ~ 08', '08 ~ 09', '09 ~ 10', '10 ~ 11', '11 ~ 12', \n",
        "            '12 ~ 13', '13 ~ 14', '14 ~ 15', '15 ~ 16', '16 ~ 17', '17 ~ 18', '18 ~ 19', \n",
        "            '19 ~ 20', '20 ~ 21', '21 ~ 22', '22 ~ 23', '23 ~ 24', '00 ~ 01']\n",
        "\n",
        "time_one_hot_dict = {}\n",
        "total_time_cnt = len(time_lst)\n",
        "\n",
        "for idx, time in enumerate(time_lst):\n",
        "    temp_encoding_lst = [0] * total_time_cnt\n",
        "    temp_encoding_lst[idx] = 1\n",
        "    time_one_hot_dict[time] = temp_encoding_lst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sm-Hr8nSQhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "day_lst = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "\n",
        "day_one_hot_dict = {}\n",
        "total_day_cnt = len(day_lst)\n",
        "\n",
        "for idx, time in enumerate(day_lst):\n",
        "    temp_encoding_lst = [0] * total_day_cnt\n",
        "    temp_encoding_lst[idx] = 1\n",
        "    day_one_hot_dict[time] = temp_encoding_lst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXc_mZ5rS3HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_day_from_date(date):\n",
        "    y, m, d = [int(x) for x in date.split(\".\")]\n",
        "    d = datetime.date(y, m, d)\n",
        "    return d.strftime(\"%a\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE_4KsqESYt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [Problem 4] Refer to the code in Step 1 and implement the code. [3pt]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPtH-g71Kdij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [Problem 5] Refer to the code in Step 1 and implement LSTM Model. [2pt]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXv13OuXmNy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [Problem 6] Write code to measure RMSE on test data and print RMSE. (Calculate RMSE in full-batch).[0.5pt]\n",
        "# Describe whether there was a change in performance compared to the model in Step 1, and if so, why this occurred. [0.5pt]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}