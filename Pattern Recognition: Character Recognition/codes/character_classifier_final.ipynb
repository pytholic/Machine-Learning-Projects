{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "***PB Assignment # 02***\n",
    "***Pattern Recognition***\n",
    "\n",
    "Raja Haseeb\n",
    "20194673\n",
    "\n",
    "FOR TAs:\n",
    "\n",
    "- Follow steps if you want to retrain models\n",
    "- I trained multiple models, but Random Forrest provides best results. So you can just comment out rest in train section and just train the Random Forrest to save time\n",
    "- Also you can just jump to bottom to load the provided trained model and just test it to save more time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/trojan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.feature import canny \n",
    "import skimage\n",
    "from skimage import data, io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage import color \n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists to save the labels (the name of the shape)\n",
    "train_dir = '/home/trojan/Desktop/pattern recognition/PB2/Implementation/data/abcde'\n",
    "save_dir = '/home/trojan/Desktop/pattern recognition/PB2/Implementation'\n",
    "character_list = ['a', 'b', 'c', 'd', 'e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(featurewise_center=True, rotation_range=10, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, \n",
    "                         channel_shift_range=0., horizontal_flip=True, vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def augmentation_keras(dir):\n",
    "    for character in character_list:\n",
    "        for file_name in os.listdir(os.path.join(dir,character)):\n",
    "                PATH = os.path.join(dir,character)\n",
    "                img = os.path.join(dir,character,file_name)\n",
    "                image = cv2.imread(img, -1)\n",
    "                image = np.expand_dims(cv2.imread(img), 0)\n",
    "                #image = image.squeeze()\n",
    "                #plt.figure()\n",
    "                #plt.imshow(image)\n",
    "                aug_iter = gen.flow(image, save_to_dir=PATH, save_prefix='aug-image-' + file_name, save_format='png')\n",
    "                aug_images = [next(aug_iter)[0].astype(np.uint8) for i in range(30)]\n",
    "                #plotImages(aug_images)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block to start augmentation\n",
    "augmentation_keras(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5\n",
    "num_trees = 100 #100\n",
    "\n",
    "#function to preprocess data\n",
    "def preprocess(images, labels):\n",
    "    features = []\n",
    "    for i in range(len(images)):\n",
    "\n",
    "        image_pca = PCA().fit_transform(images[i])\n",
    "        image_selected = image_pca[:,:2]\n",
    "        image_selected = np.reshape(image_selected, (700))\n",
    "        features.append(image_selected)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "# function to make classifier\n",
    "def classify(model, images, labels):\n",
    "\n",
    "    model.fit(images, labels)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = []\n",
    "val_accuracies = []\n",
    "models = []\n",
    "trained_models = []\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    models.append(('KNN', KNeighborsClassifier(n_neighbors=1))) #1Best\n",
    "    models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n",
    "    models.append(('SVM', SVC(random_state=seed, C=100))) #bestC=100\n",
    "    \n",
    "    #iterate through each shape\n",
    "    all_labels, all_images = [],[]\n",
    "    for character in character_list:\n",
    "        print('Getting data for: ', character)\n",
    "        for file_name in os.listdir(os.path.join(train_dir,character)):\n",
    "            all_images.append(cv2.imread(os.path.join(train_dir,character,file_name), 0))\n",
    "            #add an integer to the labels list\n",
    "            all_labels.append(character_list.index(character))\n",
    "\n",
    "    # train and validation split\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(all_images, all_labels, \n",
    "                                                                          shuffle=True, stratify=all_labels, \n",
    "                                                                          test_size=0.1, random_state=42)\n",
    "\n",
    "    print('Number of training images: ', len(train_images), '\\n')\n",
    "\n",
    "    # Preprocess (your own function)\n",
    "    train_images, train_labels = preprocess(train_images, train_labels)\n",
    "    val_images, val_labels = preprocess(val_images, val_labels)\n",
    "\n",
    "    for name, model in models:\n",
    "        \n",
    "        best_model = model\n",
    "        #train_images, train_labels = preprocess(train_images, train_labels)\n",
    "        print (name)\n",
    "        \n",
    "        # Make a classifier (your own function)\n",
    "        model = classify(model, train_images, train_labels)\n",
    "        trained_models.append(model)\n",
    "\n",
    "        # Predict the labels from the model (your own code depending the output of the train function)\n",
    "        pred_labels = model.predict(train_images)\n",
    "\n",
    "        # Calculate accuracy (Do not erase or modify here)\n",
    "        pred_acc = np.sum(pred_labels==train_labels)/len(train_labels)*100\n",
    "        print(\"Accuracy = {}\".format(pred_acc))\n",
    "\n",
    "        cm = metrics.confusion_matrix(train_labels, pred_labels)\n",
    "        print(cm, '\\n')\n",
    "        \n",
    "        # Validation\n",
    "        print('Number of validation images: ', len(val_images))\n",
    "    \n",
    "        pred_val_labels = model.predict(val_images)\n",
    "        val_acc = np.sum(pred_val_labels==val_labels)/len(val_labels)*100\n",
    "        print(\"Val Accuracy = {}\".format(val_acc), '\\n')\n",
    "        \n",
    "        val_accuracies.append(val_acc)\n",
    "        names.append(name)\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for:  a\n",
      "Getting data for:  b\n",
      "Getting data for:  c\n",
      "Getting data for:  d\n",
      "Getting data for:  e\n",
      "Number of training images:  4178 \n",
      "\n",
      "KNN\n",
      "Accuracy = 100.0\n",
      "[[834   0   0   0   0]\n",
      " [  0 835   0   0   0]\n",
      " [  0   0 837   0   0]\n",
      " [  0   0   0 836   0]\n",
      " [  0   0   0   0 836]] \n",
      "\n",
      "Number of validation images:  465\n",
      "Val Accuracy = 78.27956989247312 \n",
      "\n",
      "RF\n",
      "Accuracy = 100.0\n",
      "[[834   0   0   0   0]\n",
      " [  0 835   0   0   0]\n",
      " [  0   0 837   0   0]\n",
      " [  0   0   0 836   0]\n",
      " [  0   0   0   0 836]] \n",
      "\n",
      "Number of validation images:  465\n",
      "Val Accuracy = 82.15053763440861 \n",
      "\n",
      "SVM\n",
      "Accuracy = 99.7127812350407\n",
      "[[830   0   0   3   1]\n",
      " [  1 832   0   2   0]\n",
      " [  1   2 834   0   0]\n",
      " [  2   0   0 834   0]\n",
      " [  0   0   0   0 836]] \n",
      "\n",
      "Number of validation images:  465\n",
      "Val Accuracy = 63.44086021505376 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy = 82.15053763440861 \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=5, verbose=0,\n",
      "                       warm_start=False)\n",
      "Best Model Is RF \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose the best model\n",
    "\n",
    "best_acc = np.max(val_accuracies)\n",
    "print(\"Best Validation Accuracy = {}\".format(best_acc), '\\n')\n",
    "    \n",
    "index_best_acc = np.argmax(val_accuracies, axis=None)\n",
    "\n",
    "best_model = trained_models[index_best_acc]\n",
    "print(best_model)\n",
    "\n",
    "best_model_name = names[index_best_acc]   \n",
    "print(\"Best Model Is {}\".format(best_model_name), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"final_model\"\n",
    "model_path = os.path.join(save_dir,filename)\n",
    "pickle.dump(best_model, open(model_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=5, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "'''Model is provided in submission with report and notebook'''\n",
    "\n",
    "loaded_model = pickle.load(open(model_path, 'rb'))\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"forTA (Do not erase here)\n",
    "    test_dir = '../ForTA'\n",
    "    test_labels, test_images = [], []\n",
    "    for shape in shape_list:\n",
    "        print('Getting data for: ', shape)\n",
    "        for file_name in os.listdir(os.path.join(test_dir,shape)):\n",
    "            test_images.append(cv2.imread(os.path.join(test_dir,shape,file_name), 0))\n",
    "            #add an integer to the labels list\n",
    "            test_labels.append(shape_list.index(shape))\n",
    "\n",
    "    print('Number of test images: ', len(test_images))\n",
    "\n",
    "    test_images, test_labels = preprocess(test_images, test_labels)\n",
    "    #pred_labels = model.predict(test_images)\n",
    "    pred_labels = loaded_model.predict(test_images)   # coz we are using 'loaded_model'\n",
    "    pred_acc = np.sum(pred_labels==test_labels)/len(test_labels)*100\n",
    "    print(\"Test Accuracy = {}\".format(pred_acc))\n",
    "    \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
