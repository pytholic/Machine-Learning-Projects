{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import sepconv\n",
    "import sys\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using easydict instead of argparser because I am using notebook\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "args = edict()\n",
    "\n",
    "# Training data\n",
    "args.data_dir = '/home/trojan/Desktop/Image restoration/Homeworks/HW3/dataset/Dataet_VFI_HW3/Vimeo90K_HW3'  # training data \n",
    "args.save_dir = '/home/trojan/Desktop/Image restoration/Homeworks/HW3/result'   # results directory\n",
    "\n",
    "# Model\n",
    "args.exp_name = 'Net_SepConv'   # model to be selected\n",
    "args.finetuning = False   # to finetune the training\n",
    "args.load = None #'NetFinal'\n",
    "\n",
    "#Validation data\n",
    "args.val_data = True\n",
    "args.val_batch_size = 1   # batch size for validation data\n",
    "#args.n_threads = 8   # threads number for loading data'''\n",
    "\n",
    "# Testing data\n",
    "args.test_dir = '/home/trojan/Desktop/Image restoration/Homeworks/HW3/dataset/Dataet_VFI_HW3/ucf101_HW3'   # test dataset directory\n",
    "args.save = True\n",
    "\n",
    "# Training and Optimization\n",
    "args.patch_size = 128\n",
    "args.batch_size = 8\n",
    "args.kernel_size = 25\n",
    "args.lr = 1e-4   # learning rate for the optimizer\n",
    "args.epochs = 10   # number of training epochs\n",
    "#args.lr_step_size = 600   # decay learning rate after N epochs\n",
    "#args.lr_gamma = 0.1   # learning rate decay factor\n",
    "args.lr_decay = 100   #number of epochs to drop lr\n",
    "args.decay_type = 'step' #lr decay type\n",
    "args.loss_type = 'L1'   #Loss type\n",
    "\n",
    "args.period = 1\n",
    "args.gpu = True   # gpu index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_variable(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def set_loss(args):\n",
    "    loss_type = args.loss_type\n",
    "    if loss_type == 'MSE':\n",
    "        lossfunction = nn.MSELoss()\n",
    "    elif loss_type == 'L1':\n",
    "        lossfunction = nn.L1Loss()\n",
    "    return lossfunction\n",
    "\n",
    "def set_lr(args, epoch, optimizer):\n",
    "    lr_decay = args.lr_decay\n",
    "    decay_type = args.decay_type\n",
    "    if decay_type == 'step':\n",
    "        epoch_iter = (epoch + 1) // lr_decay\n",
    "        lr = args.lr / 2 ** epoch_iter\n",
    "    elif decay_type == 'exp':\n",
    "        k = math.log(2) / lr_decay\n",
    "        lr = args.lr * math.exp(-k * epoch)\n",
    "    elif decay_type == 'inv':\n",
    "        k = 1 / lr_decay\n",
    "        lr = args.lr / (1 + k * epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Default convolution layer to keep same kernel, padding and stride\n",
    "def default_conv(in_channel, out_channel):\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channel, out_channels=out_channel, \n",
    "        kernel_size=3, stride=1, padding=1\n",
    "    )\n",
    "\n",
    "def avg_pool():\n",
    "    return nn.AvgPool2d(kernel_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel estmation network\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.kernel_size = args.kernel_size\n",
    "        \n",
    "        def SimpleConvBlock(in_channel, out_channel):\n",
    "            return nn.Sequential(\n",
    "            default_conv(in_channel, out_channel),\n",
    "            nn.ReLU(inplace=False),\n",
    "            default_conv(out_channel, out_channel),\n",
    "            nn.ReLU(inplace=False),\n",
    "            default_conv(out_channel, out_channel),\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "\n",
    "        \n",
    "        def Upsample(channel):\n",
    "            return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            default_conv(in_channel=channel, out_channel=channel),\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "\n",
    "            \n",
    "        def SubNet(ks):\n",
    "            return nn.Sequential(\n",
    "            default_conv(in_channel=64, out_channel=64),\n",
    "            nn.ReLU(inplace=False),\n",
    "            default_conv(in_channel=64, out_channel=64),\n",
    "            nn.ReLU(inplace=False),\n",
    "            default_conv(in_channel=64, out_channel=ks),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            default_conv(in_channel=ks, out_channel=ks)\n",
    "            )\n",
    "                \n",
    "        \n",
    "        # Encoder \n",
    "        self.Conv1 = SimpleConvBlock(6, 32)\n",
    "        self.Pool1 = avg_pool()\n",
    "        self.Conv2 = SimpleConvBlock(32, 64)\n",
    "        self.Pool2 = avg_pool()\n",
    "        self.Conv3 = SimpleConvBlock(64, 128)\n",
    "        self.Pool3 = avg_pool()\n",
    "        self.Conv4 = SimpleConvBlock(128, 256)\n",
    "        self.Pool4 = avg_pool()\n",
    "        self.Conv5 = SimpleConvBlock(256, 512)\n",
    "        self.Pool5 = avg_pool()\n",
    "                \n",
    "        # Decoder \n",
    "        self.DeConv5 = SimpleConvBlock(512, 512)\n",
    "        self.Upsample5 = Upsample(512)\n",
    "        self.DeConv4 = SimpleConvBlock(512, 256)\n",
    "        self.Upsample4 = Upsample(256)\n",
    "        self.DeConv3 = SimpleConvBlock(256, 128)\n",
    "        self.Upsample3 = Upsample(128)\n",
    "        self.DeConv2 = SimpleConvBlock(128, 64)\n",
    "        self.Upsample2 = Upsample(64)\n",
    "                \n",
    "        # Subnets\n",
    "        self.Vertical1 = SubNet(self.kernel_size)\n",
    "        self.Vertical2 = SubNet(self.kernel_size)\n",
    "        self.Horizontal1 = SubNet(self.kernel_size)\n",
    "        self.Horizontal2 = SubNet(self.kernel_size)\n",
    "\n",
    "                \n",
    "    # Define forward method\n",
    "    \n",
    "    def forward(self, tensor1, tensor3):\n",
    "        \n",
    "        # Join the two tensors\n",
    "        tensorCat = torch.cat([tensor1, tensor3], 1)\n",
    "        \n",
    "        # Encoder Pass\n",
    "        OpConv1 = self.Conv1(tensorCat)\n",
    "        OpPool1 = self.Pool1(OpConv1)\n",
    "        \n",
    "        OpConv2 = self.Conv2(OpPool1)\n",
    "        OpPool2 = self.Pool2(OpConv2)\n",
    "                \n",
    "        OpConv3 = self.Conv3(OpPool2)\n",
    "        OpPool3 = self.Pool3(OpConv3)\n",
    "                \n",
    "        OpConv4 = self.Conv4(OpPool3)\n",
    "        OpPool4 = self.Pool4(OpConv4)\n",
    "                \n",
    "        OpConv5 = self.Conv5(OpPool4)\n",
    "        OpPool5 = self.Pool5(OpConv5)\n",
    "                \n",
    "        # Decoder Pass\n",
    "        OpDeconv5 = self.DeConv5(OpPool5)\n",
    "        OpUpsample5 = self.Upsample5(OpDeconv5)\n",
    "                \n",
    "        tensorCombine = OpUpsample5 + OpConv5\n",
    "                \n",
    "        OpDeconv4 = self.DeConv4(tensorCombine)\n",
    "        OpUpsample4 = self.Upsample4(OpDeconv4)\n",
    "                \n",
    "        tensorCombine = OpUpsample4 + OpConv4\n",
    "                \n",
    "        OpDeconv3 = self.DeConv3(tensorCombine)\n",
    "        OpUpsample3 = self.Upsample3(OpDeconv3)\n",
    "                \n",
    "        tensorCombine = OpUpsample3 + OpConv3\n",
    "                \n",
    "        OpDeconv2 = self.DeConv2(tensorCombine)\n",
    "        OpUpsample2 = self.Upsample2(OpDeconv2)\n",
    "                \n",
    "        tensorCombine = OpUpsample2 + OpConv2\n",
    "                                 \n",
    "        # Subnet Pass\n",
    "        Ver1 = self.Vertical1(tensorCombine)\n",
    "        Ver2 = self.Vertical2(tensorCombine)\n",
    "        Hor1 = self.Horizontal1(tensorCombine)\n",
    "        Hor2 = self.Horizontal2(tensorCombine)\n",
    "        \n",
    "        return Ver1, Ver2, Hor1, Hor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetSep(torch.nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(ConvNetSep, self).__init__()\n",
    "        \n",
    "        # Pass the arguments\n",
    "        self.kernel_size = args.kernel_size\n",
    "        self.kernel_padding = int(math.floor(kernel_size / 2.0))\n",
    "        self.estimate_kernel = Net(self.kernel_size)\n",
    "        self.epoch = args.epochs\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = args.lr)\n",
    "        self.criterion = set_loss(args)\n",
    "        \n",
    "        self.modulePad = torch.nn.ReplicationPad2d([self.kernel_padding, self.kernel_padding, \n",
    "                                                    self.kernel_padding, self.kernel_padding])\n",
    "        \n",
    "    \n",
    "    def forward(self, Frame1, Frame3):\n",
    "        h_1 = int(list(Frame1.size())[2])\n",
    "        w_1 = int(list(Frame1.size())[3])\n",
    "        h_3 = int(list(Frame3.size())[2])\n",
    "        w_3 = int(list(Frame3.size())[3])\n",
    "        \n",
    "        # Make sure frame size is same\n",
    "        if h_1 != h_3 or w_1 != w_3:\n",
    "            sys.exit('Size mismatch')\n",
    "    \n",
    "        h_pad = False\n",
    "        w_pad = False\n",
    "        \n",
    "        if w_1 % 32 != 0:\n",
    "            pad_w = 32 - (w_1 % 32)\n",
    "            Frame1 = F.pad(Frame1, (0, pad_w, 0, 0))\n",
    "            Frame3 = F.pad(Frame3, (0, pad_w, 0, 0))\n",
    "            w_pad = True\n",
    "            \n",
    "        if h_1 % 32 != 0:\n",
    "            pad_h = 32 - (h_1 % 32)\n",
    "            Frame1 = F.pad(Frame1, (0, 0, 0, pad_h))\n",
    "            Frame3 = F.pad(Frame3, (0, 0, 0, pad_h))\n",
    "            h_pad = True\n",
    "\n",
    "        Ver1, Hor1, Ver2, Hor2 = self.estimate_kernel(Frame1, Frame3)\n",
    "        \n",
    "        tenDot1 = sepconv.FunctionSepconv()(self.modulePad(Frame1), Ver1, Hor1)\n",
    "        tenDot2 = sepconv.FunctionSepconv()(self.modulePad(Frame3), Ver2, Hor2)\n",
    "        \n",
    "        Frame2 = tenDot1 + tenDot2\n",
    "        \n",
    "        if h_pad:\n",
    "            Frame2 = Frame2[:, :, 0:h_1, :]\n",
    "        if w_pad:\n",
    "            Frame2 = Frame2[:, :, :, 0:w_1]\n",
    "            \n",
    "        return Frame2, Ver1, Hor1, Ver2, Hor2\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
