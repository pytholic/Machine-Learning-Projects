{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20194673",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfG_todxMT6c",
        "colab_type": "text"
      },
      "source": [
        "CS576 Assignment #1: Image Classification using Bag of Visual Words (BoVW) \n",
        "====\n",
        "Primary TA : Yoonki Cho\n",
        "\n",
        "TA's E-mail : yoonki@kaist.ac.kr\n",
        "## Instruction\n",
        "- In this assignment, we will classify the images into five categories (aeropalne, backgrounds, car, horse, motorcycle, person) using Bag of Visual Word (BoVW) and Support Vector Machine (SVM).\n",
        "\n",
        "- Before you start the assignment, **download & unzip the file from the link below, and upload it to your Google Drive.** \n",
        "\n",
        "*Dataset link: http://www.di.ens.fr/willow/events/cvml2013/materials/practicals/category-level/practical-category-recognition-2013a-data-only.tar.gz*\n",
        " \n",
        "- We will extract the SIFT descriptors from the images and construct codebook. After that, we will encode the images to histogram features using codebook, and train the classifier using those features.\n",
        "\n",
        "- As you follow the given steps, fill in the section marked ***Problem*** with the appropriate code. There are 4 basic problems 3 additional problems in total. For each problem, you have to write a discussion of the results in the discussion section at the bottom of this page.\n",
        "\n",
        "## Submission guidelines\n",
        "- Your code and report will be all in Colab. Copy this example to your google drive and edit it to complete your assignment. \n",
        "- <font color=\"red\"> You will get the full credit **only if** you complete the code **and** write a discussion of the results in the discussion section at the bottome of this page. </font>\n",
        "- We should be able to reproduce your results using your code. Please double-check if your code runs without error and reproduces your results. Submissions failed to run or reproduce the results will get a substantial penalty. \n",
        "\n",
        "## Deliverables\n",
        "- Download your Colab notebook, and submit a zip file in a format: [StudentID].zip. Please double-check that you locate and load your pre-trained model properly.\n",
        "- Your assignment should be submitted through KLMS. All other submissions (e.g., via email) will not be considered as valid submissions. \n",
        "\n",
        "## Due date\n",
        "- **23:59:59 April 21th.**\n",
        "- Late submission is allowed until 23:59:59 April 23th.\n",
        "- Late submission will be applied 20% penalty.\n",
        "\n",
        "\n",
        "## Questions\n",
        "- Please use QnA board in KLMS as a main communication channel. When you post questions, please make it public so that all students can share the information. Please use the prefix \"[Assignment 1]\" in the subject for all questions regarding this assignment (e.g., [Assignment 1] Regarding the grading policy).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RysBzJQFeIkg",
        "colab_type": "text"
      },
      "source": [
        "## Step 0: Set the enviroments\n",
        "For this assignment, you need the special library for extracting features & training classifier (cyvlfeat & sklearn).\n",
        "This step takes about 5~15 minutes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26drrtRufRbK",
        "colab_type": "text"
      },
      "source": [
        "###  0-1: Download cyvlfeat library & conda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEjDierhsAZ7",
        "colab_type": "code",
        "outputId": "7a55eda8-e179-48db-b652-f643967a6cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# install conda on colab\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "#drive.mount ('/content/mnt', force_remount=True)\n",
        "#nb_path = '/content/notebooks'\n",
        "#os.symlink ('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "\n",
        "\n",
        "!wget -c https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh\n",
        "!chmod +x Anaconda3-5.1.0-Linux-x86_64.sh\n",
        "!bash ./Anaconda3-5.1.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "# install cyvlfeat\n",
        "# Reference : https://anaconda.org/menpo/cyvlfeat\n",
        "!conda install -c menpo cyvlfeat -y\n",
        "\n",
        "# conda setup\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-21 11:38:22--  https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/archive/Anaconda3-5.1.0-Linux-x86_64.sh [following]\n",
            "--2020-04-21 11:38:22--  https://repo.anaconda.com/archive/Anaconda3-5.1.0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577996269 (551M) [application/x-sh]\n",
            "Saving to: ‘Anaconda3-5.1.0-Linux-x86_64.sh’\n",
            "\n",
            "Anaconda3-5.1.0-Lin 100%[===================>] 551.22M   224MB/s    in 2.5s    \n",
            "\n",
            "2020-04-21 11:38:24 (224 MB/s) - ‘Anaconda3-5.1.0-Linux-x86_64.sh’ saved [577996269/577996269]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.4-hc3d631a_1 ...\n",
            "Python 3.6.4 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2017.08.26-h1d4fec5_0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: intel-openmp-2018.0.0-hc7b2577_8 ...\n",
            "installing: libgcc-ng-7.2.0-h7cc24e2_2 ...\n",
            "installing: libgfortran-ng-7.2.0-h9f7466a_2 ...\n",
            "installing: libstdcxx-ng-7.2.0-h7a57d05_2 ...\n",
            "installing: bzip2-1.0.6-h9a117a8_4 ...\n",
            "installing: expat-2.2.5-he0dffb1_0 ...\n",
            "installing: gmp-6.1.2-h6c8ec71_1 ...\n",
            "installing: graphite2-1.3.10-hf63cedd_1 ...\n",
            "installing: icu-58.2-h9c2bf20_1 ...\n",
            "installing: jbig-2.1-hdba287a_0 ...\n",
            "installing: jpeg-9b-h024ee3a_2 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: libsodium-1.0.15-hf101ebd_0 ...\n",
            "installing: libtool-2.4.6-h544aabb_3 ...\n",
            "installing: libxcb-1.12-hcd93eb1_4 ...\n",
            "installing: lzo-2.10-h49e0be7_2 ...\n",
            "installing: mkl-2018.0.1-h19d6760_4 ...\n",
            "installing: ncurses-6.0-h9df7e31_2 ...\n",
            "installing: openssl-1.0.2n-hb7f436b_0 ...\n",
            "installing: patchelf-0.9-hf79760b_2 ...\n",
            "installing: pcre-8.41-hc27e229_1 ...\n",
            "installing: pixman-0.34.0-hceecf20_3 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: unixodbc-2.3.4-hc36303a_1 ...\n",
            "installing: xz-5.2.3-h55aa19d_2 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: glib-2.53.6-h5d9569c_2 ...\n",
            "installing: hdf5-1.10.1-h9caa474_1 ...\n",
            "installing: libedit-3.1-heed3624_0 ...\n",
            "installing: libpng-1.6.34-hb9fc6fc_0 ...\n",
            "installing: libssh2-1.8.0-h9cfc8f7_4 ...\n",
            "installing: libtiff-4.0.9-h28f6b97_0 ...\n",
            "installing: libxml2-2.9.7-h26e45fe_0 ...\n",
            "installing: mpfr-3.1.5-h11a74b3_2 ...\n",
            "installing: pandoc-1.19.2.1-hea2e7c5_1 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: zeromq-4.2.2-hbedb6e5_2 ...\n",
            "installing: dbus-1.12.2-hc3f9b76_1 ...\n",
            "installing: freetype-2.8-hab7d2ae_1 ...\n",
            "installing: gstreamer-1.12.4-hb53b477_0 ...\n",
            "installing: libcurl-7.58.0-h1ad7b7a_0 ...\n",
            "installing: libxslt-1.1.32-h1312cb7_0 ...\n",
            "installing: mpc-1.0.3-hec55b23_5 ...\n",
            "installing: sqlite-3.22.0-h1bed415_0 ...\n",
            "installing: curl-7.58.0-h84994c4_0 ...\n",
            "installing: fontconfig-2.12.4-h88586e7_1 ...\n",
            "installing: gst-plugins-base-1.12.4-h33fb286_0 ...\n",
            "installing: alabaster-0.7.10-py36h306e16b_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: attrs-17.4.0-py36_0 ...\n",
            "installing: backports-1.0-py36hfa02d7e_1 ...\n",
            "installing: beautifulsoup4-4.6.0-py36h49b8c8c_1 ...\n",
            "installing: bitarray-0.8.1-py36h14c3975_1 ...\n",
            "installing: boto-2.48.0-py36h6e4cd66_1 ...\n",
            "installing: cairo-1.14.12-h77bcde2_0 ...\n",
            "installing: certifi-2018.1.18-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: click-6.7-py36h5253387_0 ...\n",
            "installing: cloudpickle-0.5.2-py36_1 ...\n",
            "installing: colorama-0.3.9-py36h489cec4_0 ...\n",
            "installing: contextlib2-0.5.5-py36h6c84a62_0 ...\n",
            "installing: dask-core-0.16.1-py36_0 ...\n",
            "installing: decorator-4.2.1-py36_0 ...\n",
            "installing: docutils-0.14-py36hb0f60f5_0 ...\n",
            "installing: entrypoints-0.2.3-py36h1aec115_2 ...\n",
            "installing: et_xmlfile-1.0.1-py36hd6bccc3_0 ...\n",
            "installing: fastcache-1.0.2-py36h14c3975_2 ...\n",
            "installing: filelock-2.0.13-py36h646ffb5_0 ...\n",
            "installing: glob2-0.6-py36he249c77_0 ...\n",
            "installing: gmpy2-2.0.8-py36hc8893dd_2 ...\n",
            "installing: greenlet-0.4.12-py36h2d503a6_0 ...\n",
            "installing: heapdict-1.0.0-py36_2 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: imagesize-0.7.1-py36h52d8127_0 ...\n",
            "installing: ipython_genutils-0.2.0-py36hb52b0d5_0 ...\n",
            "installing: itsdangerous-0.24-py36h93cc618_1 ...\n",
            "installing: jdcal-1.3-py36h4c697fb_0 ...\n",
            "installing: lazy-object-proxy-1.3.1-py36h10fcdad_0 ...\n",
            "installing: llvmlite-0.21.0-py36ha241eea_0 ...\n",
            "installing: locket-0.2.0-py36h787c0ad_1 ...\n",
            "installing: lxml-4.1.1-py36hf71bdeb_1 ...\n",
            "installing: markupsafe-1.0-py36hd9260cd_1 ...\n",
            "installing: mccabe-0.6.1-py36h5ad9710_1 ...\n",
            "installing: mistune-0.8.3-py36_0 ...\n",
            "installing: mkl-service-1.1.2-py36h17a0993_4 ...\n",
            "installing: mpmath-1.0.0-py36hfeacd6b_2 ...\n",
            "installing: msgpack-python-0.5.1-py36h6bb024c_0 ...\n",
            "installing: multipledispatch-0.4.9-py36h41da3fb_0 ...\n",
            "installing: numpy-1.14.0-py36h3dfced4_1 ...\n",
            "installing: olefile-0.45.1-py36_0 ...\n",
            "installing: pandocfilters-1.4.2-py36ha6701b7_1 ...\n",
            "installing: parso-0.1.1-py36h35f843b_0 ...\n",
            "installing: path.py-10.5-py36h55ceabb_0 ...\n",
            "installing: pep8-1.7.1-py36_0 ...\n",
            "installing: pickleshare-0.7.4-py36h63277f8_0 ...\n",
            "installing: pkginfo-1.4.1-py36h215d178_1 ...\n",
            "installing: pluggy-0.6.0-py36hb689045_0 ...\n",
            "installing: ply-3.10-py36hed35086_0 ...\n",
            "installing: psutil-5.4.3-py36h14c3975_0 ...\n",
            "installing: ptyprocess-0.5.2-py36h69acd42_0 ...\n",
            "installing: py-1.5.2-py36h29bf505_0 ...\n",
            "installing: pycodestyle-2.3.1-py36hf609f19_0 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pycrypto-2.6.1-py36h14c3975_7 ...\n",
            "installing: pycurl-7.43.0.1-py36hb7f436b_0 ...\n",
            "installing: pyodbc-4.0.22-py36hf484d3e_0 ...\n",
            "installing: pyparsing-2.2.0-py36hee85983_1 ...\n",
            "installing: pysocks-1.6.7-py36hd97a5b1_1 ...\n",
            "installing: pytz-2017.3-py36h63b9c63_0 ...\n",
            "installing: pyyaml-3.12-py36hafb9ca4_1 ...\n",
            "installing: pyzmq-16.0.3-py36he2533c7_0 ...\n",
            "installing: qt-5.6.2-h974d657_12 ...\n",
            "installing: qtpy-1.3.1-py36h3691cc8_0 ...\n",
            "installing: rope-0.10.7-py36h147e2ec_0 ...\n",
            "installing: ruamel_yaml-0.15.35-py36h14c3975_1 ...\n",
            "installing: send2trash-1.4.2-py36_0 ...\n",
            "installing: simplegeneric-0.8.1-py36_2 ...\n",
            "installing: sip-4.18.1-py36h51ed4ed_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: snowballstemmer-1.2.1-py36h6febd40_0 ...\n",
            "installing: sortedcontainers-1.5.9-py36_0 ...\n",
            "installing: sphinxcontrib-1.0-py36h6d0f590_1 ...\n",
            "installing: sqlalchemy-1.2.1-py36h14c3975_0 ...\n",
            "installing: tblib-1.3.2-py36h34cf8b6_0 ...\n",
            "installing: testpath-0.3.1-py36h8cadb63_0 ...\n",
            "installing: toolz-0.9.0-py36_0 ...\n",
            "installing: tornado-4.5.3-py36_0 ...\n",
            "installing: typing-3.6.2-py36h7da032a_0 ...\n",
            "installing: unicodecsv-0.14.1-py36ha668878_0 ...\n",
            "installing: wcwidth-0.1.7-py36hdf4376a_0 ...\n",
            "installing: webencodings-0.5.1-py36h800622e_1 ...\n",
            "installing: werkzeug-0.14.1-py36_0 ...\n",
            "installing: wrapt-1.10.11-py36h28b7045_0 ...\n",
            "installing: xlrd-1.1.0-py36h1db9f0c_1 ...\n",
            "installing: xlsxwriter-1.0.2-py36h3de1aca_0 ...\n",
            "installing: xlwt-1.3.0-py36h7b00a1f_0 ...\n",
            "installing: babel-2.5.3-py36_0 ...\n",
            "installing: backports.shutil_get_terminal_size-1.0.0-py36hfea85ff_2 ...\n",
            "installing: bottleneck-1.2.1-py36haac1ea0_0 ...\n",
            "installing: cffi-1.11.4-py36h9745a5d_0 ...\n",
            "installing: conda-verify-2.0.0-py36h98955d8_0 ...\n",
            "installing: cycler-0.10.0-py36h93f1223_0 ...\n",
            "installing: cytoolz-0.9.0-py36h14c3975_0 ...\n",
            "installing: h5py-2.7.1-py36h3585f63_0 ...\n",
            "installing: harfbuzz-1.7.4-hc5b324e_0 ...\n",
            "installing: html5lib-1.0.1-py36h2f9c1c0_0 ...\n",
            "installing: jedi-0.11.1-py36_0 ...\n",
            "installing: networkx-2.1-py36_0 ...\n",
            "installing: nltk-3.2.5-py36h7532b22_0 ...\n",
            "installing: numba-0.36.2-np114py36hc6662d5_0 ...\n",
            "installing: numexpr-2.6.4-py36hc4a3f9a_0 ...\n",
            "installing: openpyxl-2.4.10-py36_0 ...\n",
            "installing: packaging-16.8-py36ha668100_1 ...\n",
            "installing: partd-0.3.8-py36h36fd896_0 ...\n",
            "installing: pathlib2-2.3.0-py36h49efa8e_0 ...\n",
            "installing: pexpect-4.3.1-py36_0 ...\n",
            "installing: pillow-5.0.0-py36h3deb7b8_0 ...\n",
            "installing: pyqt-5.6.0-py36h0386399_5 ...\n",
            "installing: python-dateutil-2.6.1-py36h88d3b88_1 ...\n",
            "installing: pywavelets-0.5.2-py36he602eb0_0 ...\n",
            "installing: qtawesome-0.4.4-py36h609ed8c_0 ...\n",
            "installing: scipy-1.0.0-py36hbf646e7_0 ...\n",
            "installing: setuptools-38.4.0-py36_0 ...\n",
            "installing: singledispatch-3.4.0.3-py36h7a266c3_0 ...\n",
            "installing: sortedcollections-0.5.3-py36h3c761f9_0 ...\n",
            "installing: sphinxcontrib-websupport-1.0.1-py36hb5cb234_1 ...\n",
            "installing: sympy-1.1.1-py36hc6d1c1c_0 ...\n",
            "installing: terminado-0.8.1-py36_1 ...\n",
            "installing: traitlets-4.3.2-py36h674d592_0 ...\n",
            "installing: zict-0.1.3-py36h3a3bf81_0 ...\n",
            "installing: astroid-1.6.1-py36_0 ...\n",
            "installing: bleach-2.1.2-py36_0 ...\n",
            "installing: clyent-1.2.2-py36h7e57e65_1 ...\n",
            "installing: cryptography-2.1.4-py36hd09be54_0 ...\n",
            "installing: cython-0.27.3-py36h1860423_0 ...\n",
            "installing: datashape-0.5.4-py36h3ad6b5c_0 ...\n",
            "installing: distributed-1.20.2-py36_0 ...\n",
            "installing: get_terminal_size-1.0.0-haa9412d_0 ...\n",
            "installing: gevent-1.2.2-py36h2fe25dc_0 ...\n",
            "installing: imageio-2.2.0-py36he555465_0 ...\n",
            "installing: isort-4.2.15-py36had401c0_0 ...\n",
            "installing: jinja2-2.10-py36ha16c418_0 ...\n",
            "installing: jsonschema-2.6.0-py36h006f8b5_0 ...\n",
            "installing: jupyter_core-4.4.0-py36h7c827e3_0 ...\n",
            "installing: matplotlib-2.1.2-py36h0e671d2_0 ...\n",
            "installing: navigator-updater-0.1.0-py36h14770f7_0 ...\n",
            "installing: nose-1.3.7-py36hcdf7029_2 ...\n",
            "installing: pandas-0.22.0-py36hf484d3e_0 ...\n",
            "installing: pango-1.41.0-hd475d92_0 ...\n",
            "installing: patsy-0.5.0-py36_0 ...\n",
            "installing: pyflakes-1.6.0-py36h7bd6a15_0 ...\n",
            "installing: pygments-2.2.0-py36h0d3125c_0 ...\n",
            "installing: pytables-3.4.2-py36h3b5282a_2 ...\n",
            "installing: pytest-3.3.2-py36_0 ...\n",
            "installing: scikit-learn-0.19.1-py36h7aa7ec6_0 ...\n",
            "installing: wheel-0.30.0-py36hfd4bba0_1 ...\n",
            "installing: astropy-2.0.3-py36h14c3975_0 ...\n",
            "installing: bkcharts-0.2-py36h735825a_0 ...\n",
            "installing: bokeh-0.12.13-py36h2f9c1c0_0 ...\n",
            "installing: flask-0.12.2-py36hb24657c_0 ...\n",
            "installing: jupyter_client-5.2.2-py36_0 ...\n",
            "installing: nbformat-4.4.0-py36h31c9010_0 ...\n",
            "installing: pip-9.0.1-py36h6c6f9ce_4 ...\n",
            "installing: prompt_toolkit-1.0.15-py36h17d85b1_0 ...\n",
            "installing: pylint-1.8.2-py36_0 ...\n",
            "installing: pyopenssl-17.5.0-py36h20ba746_0 ...\n",
            "installing: statsmodels-0.8.0-py36h8533d0b_0 ...\n",
            "installing: dask-0.16.1-py36_0 ...\n",
            "installing: flask-cors-3.0.3-py36h2d857d3_0 ...\n",
            "installing: ipython-6.2.1-py36h88c514a_1 ...\n",
            "installing: nbconvert-5.3.1-py36hb41ffb7_0 ...\n",
            "installing: seaborn-0.8.1-py36hfad7ec4_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: ipykernel-4.8.0-py36_0 ...\n",
            "installing: odo-0.5.1-py36h90ed295_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: scikit-image-0.13.1-py36h14c3975_1 ...\n",
            "installing: anaconda-client-1.6.9-py36_0 ...\n",
            "installing: blaze-0.11.3-py36h4e06776_0 ...\n",
            "installing: jupyter_console-5.2.0-py36he59e554_1 ...\n",
            "installing: notebook-5.4.0-py36_0 ...\n",
            "installing: qtconsole-4.3.1-py36h8f73b5b_0 ...\n",
            "installing: sphinx-1.6.6-py36_0 ...\n",
            "installing: anaconda-project-0.8.2-py36h44fb852_0 ...\n",
            "installing: jupyterlab_launcher-0.10.2-py36_0 ...\n",
            "installing: numpydoc-0.7.0-py36h18f165f_0 ...\n",
            "installing: widgetsnbextension-3.1.0-py36_0 ...\n",
            "installing: anaconda-navigator-1.7.0-py36_0 ...\n",
            "installing: ipywidgets-7.1.1-py36_0 ...\n",
            "installing: jupyterlab-0.31.5-py36_0 ...\n",
            "installing: spyder-3.2.6-py36_0 ...\n",
            "installing: _ipyw_jlab_nb_ext_conf-0.1.0-py36he11e457_0 ...\n",
            "installing: jupyter-1.0.0-py36_4 ...\n",
            "installing: anaconda-5.1.0-py36_2 ...\n",
            "installing: conda-4.4.10-py36_0 ...\n",
            "installing: conda-build-3.4.1-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Anaconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Anaconda3: /usr/local\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.4.10\n",
            "  latest version: 4.8.3\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - cyvlfeat\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    six-1.14.0                 |           py36_0          27 KB\n",
            "    setuptools-46.1.3          |           py36_0         663 KB\n",
            "    mkl_random-1.0.1           |   py36h629b387_0         373 KB\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
            "    numpy-base-1.18.1          |   py36hde5b4d6_1         5.2 MB\n",
            "    readline-7.0               |       h7b6447c_5         392 KB\n",
            "    mkl-service-2.3.0          |   py36he904b0f_0         208 KB\n",
            "    pip-20.0.2                 |           py36_1         1.9 MB\n",
            "    sqlite-3.31.1              |       h7b6447c_0         2.0 MB\n",
            "    certifi-2020.4.5.1         |           py36_0         159 KB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    python-3.6.6               |       hc3d631a_0        29.4 MB\n",
            "    openssl-1.0.2u             |       h7b6447c_0         3.1 MB\n",
            "    numpy-1.18.1               |   py36h4f9e942_0           5 KB\n",
            "    mkl_fft-1.0.1              |   py36h3010b51_0         140 KB\n",
            "    libedit-3.1.20181209       |       hc058e9b_0         188 KB\n",
            "    cyvlfeat-0.5.1             |   py36h975b26e_0         2.0 MB  menpo\n",
            "    ncurses-6.1                |       hf484d3e_0         943 KB\n",
            "    mkl-2020.0                 |              166       202.1 MB\n",
            "    wheel-0.34.2               |           py36_0          49 KB\n",
            "    ca-certificates-2020.1.1   |                0         132 KB\n",
            "    vlfeat-0.9.20              |                1         199 KB  menpo\n",
            "    tk-8.6.8                   |       hbc83047_0         3.1 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       261.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:   0.1-main                   \n",
            "    blas:            1.0-mkl                    \n",
            "    cyvlfeat:        0.5.1-py36h975b26e_0  menpo\n",
            "    mkl_fft:         1.0.1-py36h3010b51_0       \n",
            "    mkl_random:      1.0.1-py36h629b387_0       \n",
            "    numpy-base:      1.18.1-py36hde5b4d6_1      \n",
            "    vlfeat:          0.9.20-1              menpo\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates: 2017.08.26-h1d4fec5_0       --> 2020.1.1-0             \n",
            "    certifi:         2018.1.18-py36_0            --> 2020.4.5.1-py36_0      \n",
            "    libedit:         3.1-heed3624_0              --> 3.1.20181209-hc058e9b_0\n",
            "    libgcc-ng:       7.2.0-h7cc24e2_2            --> 9.1.0-hdf63c60_0       \n",
            "    mkl:             2018.0.1-h19d6760_4         --> 2020.0-166             \n",
            "    mkl-service:     1.1.2-py36h17a0993_4        --> 2.3.0-py36he904b0f_0   \n",
            "    ncurses:         6.0-h9df7e31_2              --> 6.1-hf484d3e_0         \n",
            "    numpy:           1.14.0-py36h3dfced4_1       --> 1.18.1-py36h4f9e942_0  \n",
            "    openssl:         1.0.2n-hb7f436b_0           --> 1.0.2u-h7b6447c_0      \n",
            "    pip:             9.0.1-py36h6c6f9ce_4        --> 20.0.2-py36_1          \n",
            "    python:          3.6.4-hc3d631a_1            --> 3.6.6-hc3d631a_0       \n",
            "    readline:        7.0-ha6073c6_4              --> 7.0-h7b6447c_5         \n",
            "    setuptools:      38.4.0-py36_0               --> 46.1.3-py36_0          \n",
            "    six:             1.11.0-py36h372c433_1       --> 1.14.0-py36_0          \n",
            "    sqlite:          3.22.0-h1bed415_0           --> 3.31.1-h7b6447c_0      \n",
            "    tk:              8.6.7-hc745277_3            --> 8.6.8-hbc83047_0       \n",
            "    wheel:           0.30.0-py36hfd4bba0_1       --> 0.34.2-py36_0          \n",
            "    xz:              5.2.3-h55aa19d_2            --> 5.2.5-h7b6447c_0       \n",
            "    zlib:            1.2.11-ha838bed_2           --> 1.2.11-h7b6447c_3      \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "zlib 1.2.11: 100% 1.0/1 [00:00<00:00, 14.57it/s]\n",
            "blas 1.0: 100% 1.0/1 [00:00<00:00, 29.75it/s]\n",
            "xz 5.2.5: 100% 1.0/1 [00:00<00:00,  4.73it/s]               \n",
            "six 1.14.0: 100% 1.0/1 [00:00<00:00, 28.42it/s]\n",
            "setuptools 46.1.3: 100% 1.0/1 [00:00<00:00,  2.88it/s]               \n",
            "mkl_random 1.0.1: 100% 1.0/1 [00:00<00:00,  6.13it/s]      \n",
            "libgcc-ng 9.1.0: 100% 1.0/1 [00:02<00:00,  2.63s/it]              \n",
            "numpy-base 1.18.1: 100% 1.0/1 [00:02<00:00,  2.36s/it]               \n",
            "readline 7.0: 100% 1.0/1 [00:00<00:00,  5.22it/s]               \n",
            "mkl-service 2.3.0: 100% 1.0/1 [00:00<00:00,  8.92it/s] \n",
            "pip 20.0.2: 100% 1.0/1 [00:00<00:00,  1.01it/s]               \n",
            "sqlite 3.31.1: 100% 1.0/1 [00:00<00:00,  1.53it/s]               \n",
            "certifi 2020.4.5.1: 100% 1.0/1 [00:00<00:00, 12.52it/s]\n",
            "_libgcc_mutex 0.1: 100% 1.0/1 [00:00<00:00, 28.54it/s]\n",
            "python 3.6.6: 100% 1.0/1 [00:08<00:00,  8.55s/it]               \n",
            "openssl 1.0.2u: 100% 1.0/1 [00:01<00:00,  1.15s/it]               \n",
            "numpy 1.18.1: 100% 1.0/1 [00:00<00:00, 30.81it/s]\n",
            "mkl_fft 1.0.1: 100% 1.0/1 [00:00<00:00, 12.39it/s]\n",
            "libedit 3.1.20181209: 100% 1.0/1 [00:00<00:00,  8.44it/s]               \n",
            "cyvlfeat 0.5.1: 100% 1.0/1 [00:03<00:00,  3.72s/it]               \n",
            "ncurses 6.1: 100% 1.0/1 [00:01<00:00,  1.11s/it]               \n",
            "mkl 2020.0: 100% 1.0/1 [01:16<00:00, 76.65s/it]                \n",
            "wheel 0.34.2: 100% 1.0/1 [00:00<00:00, 17.48it/s]\n",
            "ca-certificates 2020.1.1: 100% 1.0/1 [00:00<00:00, 14.08it/s]\n",
            "vlfeat 0.9.20: 100% 1.0/1 [00:02<00:00,  2.78s/it]               \n",
            "tk 8.6.8: 100% 1.0/1 [00:01<00:00,  1.20s/it]               \n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3985gb9aOypG",
        "colab_type": "text"
      },
      "source": [
        "###  0-2: Connect to your Google Drive.\n",
        "\n",
        "It is required for loading the data.\n",
        "\n",
        "Enter your authorization code to access your drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKffRxrvDSJX",
        "colab_type": "code",
        "outputId": "7a40dc18-6373-4fa7-b91c-7d257b25bd13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_nlXkr7RAOK",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G29DjQXGREow",
        "colab_type": "code",
        "outputId": "567605bf-e500-486f-f041-91b668504160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QupxSolNRToP",
        "colab_type": "code",
        "outputId": "4637b747-b09e-4b36-b8ce-4de91cde6e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'      model-tuned.h5\t\t    'patch photoshop'\n",
            "'CV assignments'      'model-tuned_weights (1).h5'  'project code'\n",
            " gre\t\t       model-tuned_weights.h5\t    'report fyp'\n",
            "'model-tuned (1).h5'   passwords\t\t    'sdcard project codes'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bypm5tteROL",
        "colab_type": "text"
      },
      "source": [
        "### 0-3: Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W88TOaCsxpfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cyvlfeat\n",
        "import time\n",
        "import scipy\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xv7wrsXBO-w",
        "colab_type": "text"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTq8GkOJBN4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_dist(x, y):\n",
        "    \"\"\"\n",
        "    :param x: [m, d]\n",
        "    :param y: [n, d]\n",
        "    :return:[m, n]\n",
        "    \"\"\"\n",
        "    m, n = x.shape[0], y.shape[0]    \n",
        "    eps = 1e-6 \n",
        "\n",
        "    xx = np.tile(np.power(x, 2).sum(axis=1), (n,1)) #[n, m]\n",
        "    xx = np.transpose(xx) # [m, n]\n",
        "    yy = np.tile(np.power(y, 2).sum(axis=1), (m,1)) #[m, n]\n",
        "    xy = np.matmul(x, np.transpose(y)) # [m, n]\n",
        "    dist = np.sqrt(xx + yy - 2*xy + eps)\n",
        "\n",
        "    return dist\n",
        "\n",
        "def read_img(image_path):\n",
        "    img = Image.open(image_path).convert('L')\n",
        "    img = img.resize((480, 480))\n",
        "    return np.float32(np.array(img)/255.)\n",
        "\n",
        "def read_txt(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = f.read()\n",
        "    return data.split()\n",
        "    \n",
        "\n",
        "    \n",
        "def dataset_setup(data_dir):\n",
        "    train_file_list = []\n",
        "    val_file_list = []\n",
        "\n",
        "    for class_name in ['aeroplane','background','car','horse','motorbike','person']:\n",
        "        train_txt_path = os.path.join(data_dir, class_name+'_train.txt')\n",
        "        train_file_list.append(np.array(read_txt(train_txt_path)))\n",
        "        val_txt_path = os.path.join(data_dir, class_name+'_val.txt')\n",
        "        val_file_list.append(np.array(read_txt(val_txt_path)))\n",
        "\n",
        "    train_file_list = np.unique(np.concatenate(train_file_list))\n",
        "    val_file_list = np.unique(np.concatenate(val_file_list))\n",
        "\n",
        "    f = open(os.path.join(data_dir, \"train.txt\"), 'w')\n",
        "    for i in range(train_file_list.shape[0]):\n",
        "        data = \"%s\\n\" % train_file_list[i]\n",
        "        f.write(data)\n",
        "    f.close()\n",
        "\n",
        "    f = open(os.path.join(data_dir, \"val.txt\"), 'w')\n",
        "    for i in range(val_file_list.shape[0]):\n",
        "        data = \"%s\\n\" % val_file_list[i]\n",
        "        f.write(data)\n",
        "    f.close()\n",
        "\n",
        "def load_train_data(data_dir):\n",
        "    dataset_setup(data_dir)\n",
        "    num_proc = 12 # num_process\n",
        "\n",
        "    txt_path = os.path.join(data_dir, 'train.txt')\n",
        "    file_list = read_txt(txt_path)\n",
        "    image_paths = [os.path.join(data_dir+'/images', file_name+'.jpg') for file_name in file_list]\n",
        "    with multiprocessing.Pool(num_proc) as pool:\n",
        "      imgs = pool.map(read_img, image_paths)\n",
        "      imgs = np.array(imgs)\n",
        "      idxs = np.array(file_list)\n",
        "\n",
        "    return imgs, idxs\n",
        "\n",
        "def load_val_data(data_dir):\n",
        "    dataset_setup(data_dir)\n",
        "    num_proc = 12 # num_process\n",
        "\n",
        "    txt_path = os.path.join(data_dir, 'val.txt')\n",
        "    file_list = read_txt(txt_path)\n",
        "    image_paths = [os.path.join(data_dir+'/images', file_name+'.jpg') for file_name in file_list]\n",
        "    with multiprocessing.Pool(num_proc) as pool:\n",
        "      imgs = pool.map(read_img, image_paths)\n",
        "      imgs = np.array(imgs)\n",
        "      idxs = np.array(file_list)\n",
        "    \n",
        "    return imgs, idxs\n",
        "\n",
        "def get_labels(idxs, target_idxs):\n",
        "    \"\"\"\n",
        "    Get the labels from file index(name).\n",
        "\n",
        "    :param idxs(numpy.array): file index(name). shape:[num_images, ]\n",
        "    :param target_idxs(numpy.array): target index(name). shape:[num_target,]\n",
        "    :return(numpy.array): Target label(Binary label consisting of True and False). shape:[num_images,]\n",
        "    \"\"\"\n",
        "    return np.isin(idxs, target_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c5F-N9wfzZW",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "797O4dkG7Z2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category = ['aeroplane', 'car', 'horse', 'motorbike', 'person'] # DON'T MODIFY THIS.\n",
        "\n",
        "'''\n",
        "Set your data path for loading images & labels.\n",
        "Example) data_dir = '/gdrive/My Drive/data'\n",
        "'''\n",
        "data_dir = '/content/drive/My Drive/CV assignments/assignment1/practical-category-recognition-2013a/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3rsjTK3k690s"
      },
      "source": [
        "### 2-1. (**Problem 1**): SIFT descriptor extraction & Save the descriptors (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifzCFBMl7rx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SIFT_extraction(imgs):\n",
        "  \"\"\"\n",
        "  Extract Local SIFT descriptors from images using cyvlfeat.sift.sift().\n",
        "  Refer to https://github.com/menpo/cyvlfeat\n",
        "  You should set the parameters of cyvlfeat.sift.sift() as bellow.\n",
        "  1.compute_descriptor = True 2.float_descriptors = True\n",
        "\n",
        "  :param train_imgs(numpy.array): Gray-scale images in Numpy array format. shape:[num_images, width_size, height_size]\n",
        "  :return(numpy.array): SIFT descriptors. shape:[num_images, ], ndarray with object(descripotrs)\n",
        "  \"\"\"\n",
        "  sift_descriptors = []\n",
        "  for image in imgs:\n",
        "    frames, desc = cyvlfeat.sift.sift(image, compute_descriptor=True, float_descriptors=True)\n",
        "    sift_descriptors.append(desc)\n",
        "  return np.array(sift_descriptors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmVgUvbVYS2x",
        "colab_type": "text"
      },
      "source": [
        "### 2-2. (**Problem 2**):: Codebook(Bag of Visual Words) construction (10pt)\n",
        "In this step, you will construct the codebook using K-means clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcN66JCX7oec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_codebook(des, k):\n",
        "  \"\"\"\n",
        "  Construct the codebook with visual codewords using k-means clustering.\n",
        "  In this step, you should use cyvlfeat.kmeans.kmeans().\n",
        "  Refer to https://github.com/menpo/cyvlfeat\n",
        "\n",
        "  :param des(numpy.array): Descriptors. shape:[num_images, num_des_of_each_img, 128]\n",
        "  :param k(int): Number of visual words.\n",
        "  :return(numpy.array): Bag of visual words shape:[k, 128]\n",
        "  \"\"\"\n",
        "  descriptors = []\n",
        "  # Collect all descriptors in one array [num_images*num_des_of_each_img, 128]\n",
        "  for img_descriptors in des:\n",
        "    for descriptor in img_descriptors:\n",
        "      descriptors.append(descriptor)\n",
        "  descriptors = np.array(descriptors)\n",
        "  return cyvlfeat.kmeans.kmeans(descriptors, k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH92-UOaYiM2",
        "colab_type": "text"
      },
      "source": [
        "### 2-3. (**Problem 3**): Encode images to histogram feature based on codewords (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPQErulqCEKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(des, codebook):\n",
        "  \"\"\"\n",
        "  Construct the Bag-of-visual-Words histogram features for images using the codebook.\n",
        "  HINT: Refer to helper functions.\n",
        "\n",
        "  :param des(numpy.array): Descriptors.  shape:[num_images, num_des_of_each_img, 128]\n",
        "  :param codebook(numpy.array): Bag of visual words. shape:[k, 128]\n",
        "  :return(numpy.array): Bag of visual words shape:[num_images, k]\n",
        "\n",
        "  \"\"\"\n",
        "  # YOUR CODE HERE\n",
        "  BoVW = []\n",
        "  for img_des in des:\n",
        "    cluster_frequency = [0 for i in range(codebook.shape[0])]\n",
        "    dist = euclidean_dist(img_des, codebook) # Distance between descriptors and cluster centers\n",
        "    for des_dist in dist:\n",
        "      min_index = np.argmin(des_dist) # Index of the cluster center closest to descriptor (0~k-1)\n",
        "      cluster_frequency[min_index]+= 1\n",
        "    BoVW.append(cluster_frequency)\n",
        "  return np.array(BoVW)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJwCm_b3YwYe",
        "colab_type": "text"
      },
      "source": [
        "## Step 3. (**Problem 4**): Train the classifiers (10pt)\n",
        "Train a classifier using the sklearn library (SVC) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9gOjAvXXGJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkFInH3bDJPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classifier(features, labels, svm_params):\n",
        "  \"\"\"\n",
        "  Train the SVM classifier using sklearn.svm.svc()\n",
        "  Refer to https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "  :param features(numpy.array): Historgram representation. shape:[num_images, dim_feature]\n",
        "  :param labels(numpy.array): Target label(binary). shape:[num_images,]\n",
        "  :return(sklearn.svm.SVC): Trained classifier\n",
        "  \"\"\"\n",
        "  # Your code here\n",
        "  reg = svm_params['C']\n",
        "  kernel = svm_params['kernel']\n",
        "  clf = SVC(C=reg, kernel=kernel)\n",
        "  clf.fit(features, labels)\n",
        "  return clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNvZlykjWfyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Trainer(feat_params, svm_params):\n",
        "    \n",
        "    \"\"\"\n",
        "    Train the SVM classifier.\n",
        "\n",
        "    :param feat_params(dict): parameters for feature extraction.\n",
        "        ['extractor'](function pointer): function for extrat local descriptoers. (e.g. SIFT_extraction, DenseSIFT_extraction, etc)\n",
        "        ['num_codewords'](int):\n",
        "        ['result_dir'](str): Diretory to save codebooks & results.\n",
        "        \n",
        "    :param svm_params(dict): parameters for classifier training.\n",
        "        ['C'](float): Regularization parameter.\n",
        "        ['kernel'](str): Specifies the kernel type to be used in the algorithm.\n",
        "   \n",
        "    :return(sklearn.svm.SVC): trained classifier\n",
        "    \"\"\"\n",
        "    \n",
        "    extractor = feat_params['extractor']\n",
        "    k = feat_params['num_codewords']\n",
        "    result_dir = feat_params['result_dir']\n",
        "    \n",
        "    if not os.path.isdir(result_dir):\n",
        "        os.mkdir(result_dir)\n",
        "    \n",
        "    print(\"Load the training data...\")\n",
        "    start_time = time.time()\n",
        "    train_imgs, train_idxs = load_train_data(data_dir)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "    \n",
        "    print(\"Extract the local descriptors...\")\n",
        "    start_time = time.time()\n",
        "    train_des = extractor(train_imgs)\n",
        "    np.save(os.path.join(result_dir, 'train_des.npy'), train_des)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "    \n",
        "    del train_imgs\n",
        "    \n",
        "    print(\"Construct the bag of visual words...\")\n",
        "    start_time = time.time()\n",
        "    codebook = get_codebook(train_des, k)\n",
        "    np.save(os.path.join(result_dir, 'codebook.npy'), codebook)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    print(\"Extract the image features...\")\n",
        "    start_time = time.time()    \n",
        "    train_features = extract_features(train_des, codebook)\n",
        "    np.save(os.path.join(result_dir, 'train_features.npy'), train_features)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    del train_des, codebook\n",
        "    \n",
        "    print('Train the classifiers...')\n",
        "    accuracy = 0\n",
        "    models = {}\n",
        "    \n",
        "    for class_name in category:\n",
        "        target_idxs = np.array([read_txt(os.path.join(data_dir, '{}_train.txt'.format(class_name)))])\n",
        "        target_labels = get_labels(train_idxs, target_idxs)\n",
        "        \n",
        "        models[class_name] = train_classifier(train_features, target_labels, svm_params)\n",
        "        train_accuracy = models[class_name].score(train_features, target_labels) \n",
        "        print('{} Classifier train accuracy:  {:.4f}'.format(class_name ,train_accuracy))\n",
        "        accuracy += train_accuracy\n",
        "    \n",
        "    print('Average train accuracy: {:.4f}'.format(accuracy/len(category)))\n",
        "    del train_features, target_labels, target_idxs\n",
        "\n",
        "    return models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkM12brUWjLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_params = {'extractor': SIFT_extraction, 'num_codewords':1024, 'result_dir':os.path.join(data_dir,'sift_1024')}\n",
        "svm_params = {'C': 1, 'kernel': 'linear'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v_QngFiWlRZ",
        "colab_type": "code",
        "outputId": "24570ea3-c61a-428f-b0f5-5f4e64162884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "models = Trainer(feat_params, svm_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load the training data...\n",
            "15.4854 seconds\n",
            "Extract the local descriptors...\n",
            "332.4702 seconds\n",
            "Construct the bag of visual words...\n",
            "3531.9912 seconds\n",
            "Extract the image features...\n",
            "39.2368 seconds\n",
            "Train the classifiers...\n",
            "aeroplane Classifier train accuracy:  1.0000\n",
            "car Classifier train accuracy:  1.0000\n",
            "horse Classifier train accuracy:  1.0000\n",
            "motorbike Classifier train accuracy:  1.0000\n",
            "person Classifier train accuracy:  0.9442\n",
            "Average train accuracy: 0.9888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLnPCHFOalSk",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Test the classifier on validation set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EN0ZUiXWoI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Test(feat_params, models):\n",
        "    \"\"\"\n",
        "    Test the SVM classifier.\n",
        "\n",
        "    :param feat_params(dict): parameters for feature extraction.\n",
        "        ['extractor'](function pointer): function for extrat local descriptoers. (e.g. SIFT_extraction, DenseSIFT_extraction, etc)\n",
        "        ['num_codewords'](int):\n",
        "        ['result_dir'](str): Diretory to load codebooks & save results.\n",
        "        \n",
        "    :param models(dict): dict of classifiers(sklearn.svm.SVC)\n",
        "    \"\"\"\n",
        "    \n",
        "    extractor = feat_params['extractor']\n",
        "    k = feat_params['num_codewords']\n",
        "    result_dir = feat_params['result_dir']\n",
        "    \n",
        "    print(\"Load the validation data...\")\n",
        "    start_time = time.time()\n",
        "    val_imgs, val_idxs = load_val_data(data_dir)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "    \n",
        "    print(\"Extract the local descriptors...\")\n",
        "    start_time = time.time()\n",
        "    val_des = extractor(val_imgs)\n",
        "    np.save(os.path.join(result_dir, 'val_des.npy'), val_des)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "    \n",
        "    \n",
        "    del val_imgs\n",
        "    codebook = np.load(os.path.join(result_dir, 'codebook.npy'))\n",
        "    \n",
        "    print(\"Extract the image features...\")\n",
        "    start_time = time.time()    \n",
        "    val_features = extract_features(val_des, codebook)\n",
        "    np.save(os.path.join(result_dir, 'val_features.npy'), val_features)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    del val_des, codebook\n",
        "\n",
        "    print('Test the classifiers...')\n",
        "    accuracy = 0\n",
        "    for class_name in category:\n",
        "        target_idxs = np.array([read_txt(os.path.join(data_dir, '{}_val.txt'.format(class_name)))])\n",
        "        target_labels = get_labels(val_idxs, target_idxs)\n",
        "        \n",
        "        val_accuracy = models[class_name].score(val_features, target_labels)\n",
        "        print('{} Classifier validation accuracy:  {:.4f}'.format(class_name ,val_accuracy))\n",
        "        accuracy += val_accuracy\n",
        "    \n",
        "    del val_features, target_idxs, target_labels\n",
        "\n",
        "    print('Average validation accuracy: {:.4f}'.format(accuracy/len(category)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsKJ6Q1Kp53b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_params = {'extractor': SIFT_extraction, 'num_codewords':1024, 'result_dir':os.path.join(data_dir,'sift_1024')}\n",
        "svm_params = {'C': 1, 'kernel': 'linear'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B7u2fsnp8LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test(feat_params, models)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQel44Nzpjel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''test results for sift are here, I stored results before than reran it and cacelled it, \n",
        "did not have time to run whole thing again, so i am pasting results here\n",
        "#sift:'''\n",
        "\n",
        "Load the validation data...\n",
        "128.1995 seconds\n",
        "Extract the local descriptors...\n",
        "305.2047 seconds\n",
        "Extract the image features...\n",
        "40.9209 seconds\n",
        "Test the classifiers...\n",
        "aeroplane Classifier validation accuracy:  0.9406\n",
        "car Classifier validation accuracy:  0.7425\n",
        "horse Classifier validation accuracy:  0.9006\n",
        "motorbike Classifier validation accuracy:  0.9163\n",
        "person Classifier validation accuracy:  0.5833\n",
        "Average validation accuracy: 0.8167"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3X0BFLm756K",
        "colab_type": "text"
      },
      "source": [
        "## **Additional problem 1**: Implement Dense SIFT (10pt)\n",
        "Modify the feature extractor using the dense SIFT and evaluate the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaY4kqQE8PXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DenseSIFT_extraction(imgs):\n",
        "  \"\"\"\n",
        "  Extract Dense SIFT descriptors from images using cyvlfeat.sift.dsift().\n",
        "  Refer to https://github.com/menpo/cyvlfeat\n",
        "  You should set the parameters of cyvlfeat.sift.dsift() as bellow.\n",
        "    1.step = 12  2.float_descriptors = True\n",
        "\n",
        "  :param train_imgs(numpy.array): Gray-scale images in Numpy array format. shape:[num_images, width_size, height_size]\n",
        "  :return(numpy.array): Dense SIFT descriptors. shape:[num_images, num_des_of_each_img, 128]\n",
        "  \"\"\"\n",
        "  # YOUR CODE HERE\n",
        "  dsift_descriptors = []\n",
        "  for image in imgs:\n",
        "    frames, desc = cyvlfeat.sift.dsift(image, step = 12, float_descriptors=True)\n",
        "    dsift_descriptors.append(desc)\n",
        "  return np.array(dsift_descriptors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h8BRyHfJ-Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_params = {'extractor': DenseSIFT_extraction, 'num_codewords':1024, 'result_dir':os.path.join(data_dir,'dsift_1024')}\n",
        "svm_params = {'C': 1, 'kernel': 'linear'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sK9K5PxJ-co",
        "colab_type": "code",
        "outputId": "23d240ad-7e56-4af0-caf4-5d3fbceb09fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "models = Trainer(feat_params, svm_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load the training data...\n",
            "136.9033 seconds\n",
            "Extract the local descriptors...\n",
            "543.9498 seconds\n",
            "Construct the bag of visual words...\n",
            "8691.6206 seconds\n",
            "Extract the image features...\n",
            "91.2403 seconds\n",
            "Train the classifiers...\n",
            "aeroplane Classifier train accuracy:  1.0000\n",
            "car Classifier train accuracy:  1.0000\n",
            "horse Classifier train accuracy:  1.0000\n",
            "motorbike Classifier train accuracy:  1.0000\n",
            "person Classifier train accuracy:  0.9765\n",
            "Average train accuracy: 0.9953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788kfa5XJ_DJ",
        "colab_type": "code",
        "outputId": "6caee90d-dc2d-47d3-fa75-1f437e383d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "Test(feat_params, models)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load the validation data...\n",
            "112.7272 seconds\n",
            "Extract the local descriptors...\n",
            "557.4045 seconds\n",
            "Extract the image features...\n",
            "88.9116 seconds\n",
            "Test the classifiers...\n",
            "aeroplane Classifier validation accuracy:  0.9543\n",
            "car Classifier validation accuracy:  0.7963\n",
            "horse Classifier validation accuracy:  0.9163\n",
            "motorbike Classifier validation accuracy:  0.9131\n",
            "person Classifier validation accuracy:  0.5728\n",
            "Average validation accuracy: 0.8306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWyoU1yG7qhf",
        "colab_type": "text"
      },
      "source": [
        "## **Additional problem 2**: Implement the Spatial Pyramid (10pt)\n",
        "Modify the feature extractor using the spatial pyramid matching and evaluate the performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJJpyKo98QQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def SpatialPyramid(des, codebook):\n",
        "  \"\"\"\n",
        "  Extract image representation with Spatial Pyramid Matching using your DenseSIFT descripotrs & codebook.\n",
        "\n",
        "  :param des(numpy.array): DenseSIFT Descriptors.  shape:[num_images, num_des_of_each_img, 128]\n",
        "  :param codebook(numpy.array): Bag of visual words. shape:[k, 128]\n",
        "\n",
        "  :return(numpy.array): Image feature using SpatialPyramid [num_images, features_dim]\n",
        "  \"\"\"\n",
        "  # YOUR CODE HERE\n",
        "  # form histogram with Spatial Pyramid Matching upto level L with codebook kmeans and k codewords\n",
        "def SpatialPyramid(L, img, kmeans, k):\n",
        "    W = img.shape[1]\n",
        "    H = img.shape[0]   \n",
        "    h = []\n",
        "    for l in range(L+1):\n",
        "        w_step = math.floor(W/(2**l))\n",
        "        h_step = math.floor(H/(2**l))\n",
        "        x, y = 0, 0\n",
        "        for i in range(1,2**l + 1):\n",
        "            x = 0\n",
        "            for j in range(1, 2**l + 1):                \n",
        "                desc = DenseSIFT_extraction(img[y:y+h_step, x:x+w_step])                \n",
        "                #print(\"type:\",desc is None, \"x:\",x,\"y:\",y, \"desc_size:\",desc is None)\n",
        "                predict = kmeans.predict(desc)\n",
        "                histo = np.bincount(predict, minlength=k).reshape(1,-1).ravel()\n",
        "                weight = 2**(l-L)\n",
        "                h.append(weight*histo)\n",
        "                x = x + w_step\n",
        "            y = y + h_step\n",
        "            \n",
        "    hist = np.array(h).ravel()\n",
        "    # normalize hist\n",
        "    dev = np.std(hist)\n",
        "    hist -= np.mean(hist)\n",
        "    hist /= dev\n",
        "    return hist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzFhMBMmWfI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get histogram representation for training/testing data\n",
        "def getHistogramSPM(L, data, kmeans, k):    \n",
        "    x = []\n",
        "    for i in range(len(data)):        \n",
        "        hist = getImageFeaturesSPM(L, data[i], kmeans, k)        \n",
        "        x.append(hist)\n",
        "    return np.array(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAVKLXXyx2NE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SP_Trainer(des_path, codebook_path, result_dir, svm_params):\n",
        "    \n",
        "    \"\"\"\n",
        "    Train the SVM classifier using SpatialPyramid representations.\n",
        "\n",
        "    :param des_path(str): path for loading training dataset DenseSIFT descriptors.\n",
        "    :param codebook(str): path for loading codebook for DenseSIFT descriptors.\n",
        "    :param result_dir(str): diretory to save features.\n",
        "        \n",
        "    :param svm_params(dict): parameters for classifier training.\n",
        "        ['C'](float): Regularization parameter.\n",
        "        ['kernel'](str): Specifies the kernel type to be used in the algorithm.\n",
        "   \n",
        "    :return(sklearn.svm.SVC): trained classifier\n",
        "    \"\"\"\n",
        "    train_des = np.load(des_path)\n",
        "    codebook = np.load(codebook_path)\n",
        "    train_features = SpatialPyramid(train_des, codebook)\n",
        "    np.save(os.path.join(result_dir, 'train_sp_features.npy'), train_features)\n",
        "\n",
        "    del train_des, codebook\n",
        "    \n",
        "    print('Train the classifiers...')\n",
        "    accuracy = 0\n",
        "    models = {}\n",
        "    \n",
        "    for class_name in category:\n",
        "        target_idxs = np.array([read_txt(os.path.join(data_dir, '{}_train.txt'.format(class_name)))])\n",
        "        target_labels = get_labels(train_idxs, target_idxs)\n",
        "        \n",
        "        models[class_name] = train_classifier(train_features, target_labels, svm_params)\n",
        "        train_accuracy = models[class_name].score(train_features, target_labels) \n",
        "        print('{} Classifier train accuracy:  {:.4f}'.format(class_name ,train_accuracy))\n",
        "        accuracy += train_accuracy\n",
        "    \n",
        "    print('Average train accuracy: {:.4f}'.format(accuracy/len(category)))\n",
        "    del train_features, target_labels, target_idxs\n",
        "\n",
        "    return models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q--UT0fyEyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SP_Test(des_path, codebook_path, result_dir, models):\n",
        "    \"\"\"\n",
        "    Test the SVM classifier.\n",
        "\n",
        "    :param des_path(str): path for loading validation dataset DenseSIFT descriptors.\n",
        "    :param codebook(str): path for loading codebook for DenseSIFT descriptors.\n",
        "    :param result_dir(str): diretory to save features.      \n",
        "    :param models(dict): dict of classifiers(sklearn.svm.SVC)\n",
        "\n",
        "    \"\"\" \n",
        "    val_des = np.load(des_path)\n",
        "    codebook = np.load(codebook_path)\n",
        "    val_features = SpatialPyramid(val_des, codebook)\n",
        "    np.save(os.path.join(result_dir, 'val_sp_features.npy'), train_features)\n",
        "\n",
        "\n",
        "    del val_des, codebook\n",
        "\n",
        "    print('Test the classifiers...')\n",
        "    accuracy = 0\n",
        "    for class_name in category:\n",
        "        target_idxs = np.array([read_txt(os.path.join(data_dir, '{}_val.txt'.format(class_name)))])\n",
        "        target_labels = get_labels(val_idxs, target_idxs)\n",
        "        \n",
        "        val_accuracy = models[class_name].score(val_features, target_labels)\n",
        "        print('{} Classifier validation accuracy:  {:.4f}'.format(class_name ,val_accuracy))\n",
        "        accuracy += val_accuracy\n",
        "\n",
        "    del val_features, target_idxs, target_labels\n",
        "\n",
        "    print('Average validation accuracy: {:.4f}'.format(accuracy/len(category)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS7Svvy2zTv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#YOUR CODE HERE for training & testing with Spatial Pyramid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "401jsdB_8CA1",
        "colab_type": "text"
      },
      "source": [
        "## **Additional problem 3**: Improve classification using non-linear SVM (10pt)\n",
        "Modify the classifier using the non-linear SVM and evaluate the performance. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg162rmJ8Q8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classifier(features, labels, svm_params):\n",
        "  \"\"\"\n",
        "  Train the Non-linear SVM classifier using sklearn.svm.svc()\n",
        "  Refer to https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "  :param features(numpy.array): Historgram representation. shape:[num_images, dim_feature]\n",
        "  :param labels(numpy.array): Target label(binary). shape:[num_images,]\n",
        "  :return(sklearn.svm.NuSVC): Trained classifier\n",
        "  \"\"\"\n",
        "  # Your code here\n",
        "  g = svm_params['gamma']\n",
        "  reg = svm_params['C']\n",
        "  kernel = svm_params['kernel']\n",
        "  clf = SVC(C=reg, gamma=g, kernel=kernel)\n",
        "  clf.fit(features, labels)\n",
        "  return clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gvZUiMuYVKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_params = {'extractor': SIFT_extraction, 'num_codewords':1024, 'result_dir':os.path.join(data_dir,'sift_1024')}\n",
        "svm_params = {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6ZtTO8TYnKs",
        "colab_type": "code",
        "outputId": "f7a54120-98e4-4e94-bb73-d2c516f1fdf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "models = Trainer(feat_params, svm_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load the training data...\n",
            "19.8218 seconds\n",
            "Extract the local descriptors...\n",
            "388.2665 seconds\n",
            "Construct the bag of visual words...\n",
            "4090.3224 seconds\n",
            "Extract the image features...\n",
            "50.4440 seconds\n",
            "Train the classifiers...\n",
            "aeroplane Classifier train accuracy:  1.0000\n",
            "car Classifier train accuracy:  1.0000\n",
            "horse Classifier train accuracy:  1.0000\n",
            "motorbike Classifier train accuracy:  1.0000\n",
            "person Classifier train accuracy:  1.0000\n",
            "Average train accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VldA8DQdYnoo",
        "colab_type": "code",
        "outputId": "9a402594-871c-4f7c-be44-3931cfb5eda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "Test(feat_params, models)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load the validation data...\n",
            "19.4873 seconds\n",
            "Extract the local descriptors...\n",
            "364.3087 seconds\n",
            "Extract the image features...\n",
            "51.0572 seconds\n",
            "Test the classifiers...\n",
            "aeroplane Classifier validation accuracy:  0.9491\n",
            "car Classifier validation accuracy:  0.8638\n",
            "horse Classifier validation accuracy:  0.9402\n",
            "motorbike Classifier validation accuracy:  0.9495\n",
            "person Classifier validation accuracy:  0.6027\n",
            "Average validation accuracy: 0.8610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b8Z-UnocePF",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"blue\"> Discussion and Analysis </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCn1KAvNc38r",
        "colab_type": "text"
      },
      "source": [
        "Please write discussions on the results above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2WTW9s-qe_M",
        "colab_type": "text"
      },
      "source": [
        "# **SIFT vs DSIFT:**\n",
        "\n",
        "According to the results, we see that dense sift provides better validation accuracy compared to regular sift. With dense SIFT you get a SIFT descriptor at every location, while with normal sift you get a SIFT descriptions at the locations determined by Lowe's algorithm.\n",
        "\n",
        "Dense SIFT collects more features at each location and scale in an image, increasing recognition accuracy accordingly. However, computational complexity will always be an issue for it (in relation to normal SIFT). As we can see in the results above, training time for dense sift is almost 2-3 times larger than regular sift.\n",
        "\n",
        "So the choice of which one to use depends upon the application and the accuracy/speed trade-off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPxdYKcsrXLS",
        "colab_type": "text"
      },
      "source": [
        "# **Non-Linear SVM:**\n",
        "\n",
        "In the case of high dimensional problems, linear SVMs tend to perform very well, like in the case of text classification (see for example the classic paper Text Categorization with Support Vector Machines: Learning with Many Relevant Features). It is shown how in the case of a high dimensional, sparse problem with few irrelevant features, linear SVMs achieve great performance.\n",
        "\n",
        "Non-linear kernel machines tend to dominate when the number of dimensions is smaller. In general, non-linear SVMs will achieve better performance, but in the circumstances referred above, that difference might not be significant, and linear SVMs are much faster to train.\n",
        "\n",
        "The curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces (often with hundreds or thousands of dimensions) that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience.\n",
        "\n",
        "In that case, SVM with linear kernel seems to be fine since the decision boundary is linear and everything can be run through relatively quickly.\n",
        "\n",
        "However, for SVM with non-linear kernel such as RBF, since the decision boundary is non-linear and can take any arbitrary shape, solving kernelized SVM can take a huge amount of time and is subject to over-fitting.\n",
        "\n",
        "According to the results, using non-linear SVM with 'rbf' kernel improves accuracy significantly (6-7%), even with the regular sift. This shows that our data might not that high dimentional, and non-linear SVM hence provides better accuracy. Hence higher capacity is better. Tuning the hyperparameters can help further increase the testing accuracy.\n",
        "\n",
        "So first we can try a linear mode and see if it meets our requriements.If not,try a low-capacity non-linear model. Measure the results. How well does it work? To what extent does it meet your requirements? Iteratively increase the capacity of your non-linear model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1bNkD9zPH2L",
        "colab_type": "text"
      },
      "source": [
        "## Spatial Pyramid\n",
        "\n",
        "I tried the spatial pyramid part but I was not able to finish it. I was stuck.\n",
        "I did wrtie some code but couldn't get results.\n"
      ]
    }
  ]
}